{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\zyc\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\"\"\"\n",
    "1.Data generator\n",
    "    a. Loads vocab\n",
    "    b. Loads image features\n",
    "    c. provide data for training\n",
    "2. Builds image caption model.\n",
    "3. Trains the model.\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow.io.gfile as gfile\n",
    "from tensorflow.compat.v1 import logging\n",
    "import pprint\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "input_description_file = \"./image_caption_data/results_20130124.token\"\n",
    "input_img_feature_file = \"./image_caption_data/feature_extraction_inception_v3\"\n",
    "input_vocab_file = \"./image_caption_data/vocab.txt\"\n",
    "output_dir = \"./image_caption_data/local_run\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "class HParams:\n",
    "    def __init__(self,\n",
    "                 num_vocab_word_threshold,\n",
    "                 num_embedding_nodes,\n",
    "                 num_timesteps,\n",
    "                 num_lstm_nodes,\n",
    "                 num_lstm_layers,\n",
    "                 num_fc_nodes,\n",
    "                 batch_size,\n",
    "                 cell_type,\n",
    "                 clip_lstm_grades,\n",
    "                 learning_rate,\n",
    "                 keep_prob,\n",
    "                 log_frequent,\n",
    "                 save_frequent):\n",
    "        self.num_vocab_word_threshold = num_vocab_word_threshold\n",
    "        self.num_embedding_nodes = num_embedding_nodes\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.num_lstm_nodes = num_lstm_nodes\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        self.num_fc_nodes = num_fc_nodes\n",
    "        self.batch_size = batch_size\n",
    "        self.cell_type = cell_type\n",
    "        self.clip_lstm_grades = clip_lstm_grades\n",
    "        self.learning_rate = learning_rate\n",
    "        self.keep_prob = keep_prob\n",
    "        self.log_frequent = log_frequent\n",
    "        self.save_frequent = save_frequent\n",
    "\n",
    "def get_default_params():\n",
    "    return HParams(\n",
    "        num_vocab_word_threshold = 3,\n",
    "        num_embedding_nodes = 32,\n",
    "        num_timesteps = 10,\n",
    "        num_lstm_nodes = [64,64],\n",
    "        num_lstm_layers = 2,\n",
    "        num_fc_nodes = 32,\n",
    "        batch_size = 80,\n",
    "        cell_type = \"lstm\",\n",
    "        clip_lstm_grades = 1.0,\n",
    "        learning_rate = 0.001,\n",
    "        keep_prob = 0.8,\n",
    "        log_frequent = 10,\n",
    "        save_frequent = 100\n",
    "    )\n",
    "\n",
    "hps = get_default_params()\n",
    "print(hps.save_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, filename, word_num_threshold):\n",
    "        self._id_to_word = {}\n",
    "        self._word_to_id = {}\n",
    "        self._unk = -1\n",
    "        self._eos = -1\n",
    "        self._word_num_threshold = word_num_threshold\n",
    "        self._read_dict(filename)\n",
    "\n",
    "    def _read_dict(self, filename):\n",
    "        with gfile.GFile(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            word, occurrence = line.strip('\\r\\n').split('\\t')\n",
    "            occurrence = int(occurrence)\n",
    "            if occurrence < self._word_num_threshold:\n",
    "                continue\n",
    "            idx = len(self._id_to_word)\n",
    "            if word == '<UNK>':\n",
    "                self._unk = idx\n",
    "            elif word == '.':\n",
    "                self._eos = idx\n",
    "            if word in self._word_to_id or idx in self._id_to_word:\n",
    "                raise Exception(\"duplicate words in vocab.\")\n",
    "            self._word_to_id[word] = idx\n",
    "            self._id_to_word[idx] = word\n",
    "\n",
    "    @property\n",
    "    def unk(self):\n",
    "        return self._unk\n",
    "    @property\n",
    "    def eos(self):\n",
    "        return self._eos\n",
    "    def word_to_id(self, word):\n",
    "        return self._word_to_id.get(word, self.unk)\n",
    "    def id_to_word(self, word):\n",
    "        return self._id_to_word.get(word, '<UNK>')\n",
    "    def size(self):\n",
    "        return len(self._id_to_word)\n",
    "    def encode(self, sentence):\n",
    "        return [self.word_to_id(word) for word in sentence.split(' ')]\n",
    "    def decode(self, sentence_id):\n",
    "        words = [self.id_to_word(word_id) for word_id in sentence_id]\n",
    "        return ' '.join(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocab_size: 10875\n",
      "[1494, 389, 1, 0]\n",
      "'the of man white'\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(input_vocab_file, hps.num_vocab_word_threshold)\n",
    "vocab_size = vocab.size()\n",
    "logging.info(\"vocab_size: %d\" % vocab_size)\n",
    "pprint.pprint(vocab.encode(\"I have a dream.\"))\n",
    "pprint.pprint(vocab.decode([5, 10, 9, 20]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def parse_token_file(token_file):\n",
    "    \"\"\"Parses image description file.\"\"\"\n",
    "    img_name_to_tokens = {}\n",
    "    with gfile.GFile(token_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            img_id, description = line.strip('\\r\\n').split('\\t')\n",
    "            img_name, _ = img_id.split('#')\n",
    "            img_name_to_tokens.setdefault(img_name, [])\n",
    "            img_name_to_tokens[img_name].append(description)\n",
    "    return img_name_to_tokens\n",
    "\n",
    "def convert_token_to_id(img_name_to_tokens, vocab):\n",
    "    \"\"\"Converts tokens of each description of imgs to id.\"\"\"\n",
    "    img_name_to_tokens_id = {}\n",
    "    for img_name in img_name_to_tokens:\n",
    "        img_name_to_tokens_id.setdefault(img_name, [])\n",
    "        for description in img_name_to_tokens[img_name]:\n",
    "            token_ids = vocab.encode(description)\n",
    "            img_name_to_tokens_id[img_name].append(token_ids)\n",
    "    return img_name_to_tokens_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "img_name_to_tokens = parse_token_file(input_description_file)\n",
    "img_name_to_tokens_id = convert_token_to_id(img_name_to_tokens, vocab)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:num of all imgs: 31783\n",
      "['A man in jeans is reclining on a green metal bench along a busy sidewalk and '\n",
      " 'crowded street .',\n",
      " 'A white male with a blue sweater and gray pants laying on a sidewalk bench .',\n",
      " 'A man in a blue shirt and gray pants is sleeping on a sidewalk bench .',\n",
      " 'A person is sleeping on a bench , next to cars .',\n",
      " 'A man sleeping on a bench in a city area .']\n",
      "INFO:tensorflow:num if all imgs: 31783\n",
      "[[3, 9, 4, 132, 8, 3532, 6, 1, 48, 337, 146, 139, 1, 244, 93, 7, 380, 36, 2],\n",
      " [3, 20, 179, 11, 1, 26, 284, 7, 120, 128, 297, 6, 1, 93, 146, 2],\n",
      " [3, 9, 4, 1, 26, 21, 7, 120, 128, 8, 340, 6, 1, 93, 146, 2],\n",
      " [3, 63, 8, 340, 6, 1, 146, 12, 70, 15, 518, 2],\n",
      " [3, 9, 340, 6, 1, 146, 4, 1, 112, 171, 2]]\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"num of all imgs: %d\" % len(img_name_to_tokens))\n",
    "pprint.pprint(img_name_to_tokens['2778832101.jpg'])\n",
    "logging.info(\"num if all imgs: %d\" % len(img_name_to_tokens_id))\n",
    "pprint.pprint(img_name_to_tokens_id['2778832101.jpg'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class ImageCaptionData(object):\n",
    "    \"\"\"Provides data for image caption model.\"\"\"\n",
    "    def __init__(self,\n",
    "                 image_name_to_token_id,\n",
    "                 image_feature_dir,\n",
    "                 num_timesteps,\n",
    "                 vocab,\n",
    "                 deterministic = False):\n",
    "        self._vocab = vocab\n",
    "        self._image_name_to_token_id = image_name_to_token_id\n",
    "        self._num_timesteps = num_timesteps\n",
    "        self._deterministic = deterministic\n",
    "        self._indicator = 0\n",
    "\n",
    "        self._img_feature_filenames = []\n",
    "        self._img_feature_data = []\n",
    "\n",
    "        self._all_img_feature_filepaths = []\n",
    "        for filename in gfile.listdir(image_feature_dir):\n",
    "            self._all_img_feature_filepaths.append(\n",
    "                os.path.join(image_feature_dir,filename)\n",
    "            )\n",
    "        pprint.pprint(self._all_img_feature_filepaths)\n",
    "        self._load_img_feature_pickle()\n",
    "\n",
    "        if not self._deterministic:\n",
    "            self._random_shuffle()\n",
    "\n",
    "    def _load_img_feature_pickle(self):\n",
    "        \"\"\"Load img feature data from pickle\"\"\"\n",
    "        for filepath in self._all_img_feature_filepaths:\n",
    "            logging.info(\"loading %s\" % filepath)\n",
    "            with gfile.GFile(filepath, 'rb') as  f:\n",
    "                filenames, features = cPickle.load(f,encoding = 'iso-8859-1')\n",
    "                self._img_feature_filenames += filenames\n",
    "                self._img_feature_data.append(features)\n",
    "        # 按照最后一个维度合并\n",
    "        self._img_feature_data = np.vstack(self._img_feature_data)\n",
    "        origin_shape = self._img_feature_data.shape\n",
    "        # 去掉中间两个维度\n",
    "        self._img_feature_data = np.reshape(\n",
    "            self._img_feature_data,\n",
    "            (origin_shape[0], origin_shape[3])\n",
    "        )\n",
    "        self._img_feature_filenames = np.asarray(self._img_feature_filenames)\n",
    "        print(self._img_feature_data.shape)\n",
    "        print(self._img_feature_filenames.shape)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self._img_feature_filenames)\n",
    "\n",
    "    def img_feature_size(self):\n",
    "        return self._img_feature_data.shape[1]\n",
    "\n",
    "    def _random_shuffle(self):\n",
    "        \"\"\"Shuffle data randomly.\"\"\"\n",
    "        p = np.random.permutation(self.size())\n",
    "        self._img_feature_filenames = self._img_feature_filenames[p]\n",
    "        self._img_feature_data = self._img_feature_data[p]\n",
    "\n",
    "    def img_desc(self, batch_filenames):\n",
    "        \"\"\"Gets descriptions for filenames in batch.\"\"\"\n",
    "        batch_sentence_ids = []\n",
    "        batch_wights = []\n",
    "        for filename in batch_filenames:\n",
    "            token_ids_set = self._image_name_to_token_id[filename]\n",
    "            chosen_token_ids = random.choice(token_ids_set)\n",
    "            chosen_token_ids_length = len(chosen_token_ids)\n",
    "\n",
    "            weight = [1 for i in range(chosen_token_ids_length)]\n",
    "            if chosen_token_ids_length >= self._num_timesteps:\n",
    "                chosen_token_ids = chosen_token_ids[0:self._num_timesteps]\n",
    "                weight = weight[0:self._num_timesteps]\n",
    "            else:\n",
    "                remaining_length = self._num_timesteps - chosen_token_ids_length\n",
    "                chosen_token_ids += [self._vocab.eos for i in range(remaining_length)]\n",
    "                weight += [0 for i in range(remaining_length)]\n",
    "            batch_sentence_ids.append(chosen_token_ids)\n",
    "            batch_wights.append(weight)\n",
    "        batch_sentence_ids = np.asarray(batch_sentence_ids)\n",
    "        batch_wights = np.asarray(batch_wights)\n",
    "        return batch_sentence_ids, batch_wights\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Returns next batch data.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self.size():\n",
    "            if not self._deterministic:\n",
    "                self._random_shuffle()\n",
    "            self._indicator = 0\n",
    "            end_indicator = self._indicator + batch_size\n",
    "        assert end_indicator < self.size()\n",
    "\n",
    "        batch_filenames = self._img_feature_filenames[self._indicator: end_indicator]\n",
    "        batch_img_features = self._img_feature_data[self._indicator: end_indicator]\n",
    "        # sentence_ids: [100,101,0,0,0] -> [1,1,0,0,0]\n",
    "        # batch_weights: 计算权重,不计算<UNK>的损失函数\n",
    "        batch_sentence_ids, batch_weights = self.img_desc(batch_filenames)\n",
    "        self._indicator = end_indicator\n",
    "        return batch_img_features, batch_sentence_ids, batch_weights, batch_filenames"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./image_caption_data/feature_extraction_inception_v3\\\\image_features-0.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-1.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-10.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-11.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-12.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-13.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-14.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-15.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-16.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-17.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-18.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-19.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-2.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-20.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-21.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-22.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-23.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-24.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-25.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-26.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-27.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-28.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-29.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-3.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-30.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-31.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-4.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-5.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-6.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-7.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-8.pickle',\n",
      " './image_caption_data/feature_extraction_inception_v3\\\\image_features-9.pickle']\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-0.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-1.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-10.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-11.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-12.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-13.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-14.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-15.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-16.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-17.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-18.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-19.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-2.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-20.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-21.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-22.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-23.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-24.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-25.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-26.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-27.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-28.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-29.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-3.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-30.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-31.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-4.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-5.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-6.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-7.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-8.pickle\n",
      "INFO:tensorflow:loading ./image_caption_data/feature_extraction_inception_v3\\image_features-9.pickle\n",
      "(31783, 2048)\n",
      "(31783,)\n",
      "INFO:tensorflow:img_features_dim: 2048\n",
      "INFO:tensorflow:caption_data_size: 31783\n",
      "array([[0.6223131 , 0.7207247 , 0.5549986 , ..., 0.13144982, 0.16247734,\n",
      "        0.13470842],\n",
      "       [0.72494453, 0.41048223, 0.9583032 , ..., 0.6588631 , 0.08695641,\n",
      "        0.30693564],\n",
      "       [0.36247602, 0.34631595, 0.47327524, ..., 0.8543953 , 0.7832999 ,\n",
      "        1.3928852 ],\n",
      "       [0.3938261 , 0.4230127 , 0.19002177, ..., 0.62305903, 0.01816036,\n",
      "        0.04523041],\n",
      "       [0.22755513, 0.24300358, 0.21418972, ..., 0.83067656, 0.75890464,\n",
      "        0.37123948]], dtype=float32)\n",
      "array([[   1, 1524,  356,   72,    5,  363,   11,   19,   32,  217],\n",
      "       [ 208,   14,    1,  561,   10,  659, 2197,  339,    2,    2],\n",
      "       [   3,    9,  297,    6,    5,  528,  651,   15,    0,  124],\n",
      "       [   3,    9, 1528,    5,  173,    6,    1,  161,    2,    2],\n",
      "       [   1, 2488,    4,    1, 4282,  317,  142, 2315,    7,   68]])\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "array(['4662948361.jpg', '3389458786.jpg', '445348023.jpg',\n",
      "       '3185645793.jpg', '2472678549.jpg'], dtype='<U14')\n"
     ]
    }
   ],
   "source": [
    "caption_data = ImageCaptionData(img_name_to_tokens_id,\n",
    "                                input_img_feature_file,\n",
    "                                hps.num_timesteps,\n",
    "                                vocab)\n",
    "\n",
    "img_feature_dim = caption_data.img_feature_size()\n",
    "caption_data_size = caption_data.size()\n",
    "logging.info(\"img_features_dim: %d\" % img_feature_dim)\n",
    "logging.info(\"caption_data_size: %d\" % caption_data_size)\n",
    "\n",
    "batch_img_features, batch_sentence_ids, batch_weights, batch_img_names = caption_data.next_batch(5)\n",
    "pprint.pprint(batch_img_features)\n",
    "pprint.pprint(batch_sentence_ids)\n",
    "pprint.pprint(batch_weights)\n",
    "pprint.pprint(batch_img_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\zyc\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From <ipython-input-9-ca186b5b7f78>:57: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\zyc\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-9-ca186b5b7f78>:4: BasicLSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-ca186b5b7f78>:72: MultiRNNCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-ca186b5b7f78>:75: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\zyc\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:738: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\zyc\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:744: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-9-ca186b5b7f78>:86: dropout (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "Tensor(\"embeddings/loss/ArgMax:0\", shape=(800,), dtype=int32)\n",
      "INFO:tensorflow:variable name: embeddings/embedding:0\n",
      "INFO:tensorflow:variable name: embeddings/img_feature_embed/dense/kernel:0\n",
      "INFO:tensorflow:variable name: embeddings/img_feature_embed/dense/bias:0\n",
      "INFO:tensorflow:variable name: embeddings/lstm_nn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0\n",
      "INFO:tensorflow:variable name: embeddings/lstm_nn/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0\n",
      "INFO:tensorflow:variable name: embeddings/lstm_nn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0\n",
      "INFO:tensorflow:variable name: embeddings/lstm_nn/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0\n",
      "INFO:tensorflow:variable name: embeddings/fc/fc1/kernel:0\n",
      "INFO:tensorflow:variable name: embeddings/fc/fc1/bias:0\n",
      "INFO:tensorflow:variable name: embeddings/fc/logits/kernel:0\n",
      "INFO:tensorflow:variable name: embeddings/fc/logits/bias:0\n"
     ]
    }
   ],
   "source": [
    "def create_rnn_cell(hidden_dim, cell_type):\n",
    "    \"\"\"Returns specific cell according to cell_type\"\"\"\n",
    "    if cell_type == 'lstm':\n",
    "        return tf.nn.rnn_cell.BasicLSTMCell(hidden_dim,\n",
    "                                            state_is_tuple = True)\n",
    "    elif cell_type == 'gru':\n",
    "        return tf.nn.rnn_cell.GRUCell(hidden_dim)\n",
    "    else:\n",
    "        raise Exception(\"%s type has not been supported.\" % cell_type)\n",
    "\n",
    "def dropout(cell, keep_prob):\n",
    "    \"\"\"Wrap cell with dropout.\"\"\"\n",
    "    return tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = keep_prob)\n",
    "\n",
    "def get_train_model(hps, vocab_size, img_feature_dim):\n",
    "    num_timesteps = hps.num_timesteps\n",
    "    batch_size = hps.batch_size\n",
    "\n",
    "    img_feature = tf.placeholder(tf.float32,\n",
    "                                 (batch_size, img_feature_dim))\n",
    "    sentence = tf.placeholder(tf.int32,\n",
    "                              (batch_size, num_timesteps))\n",
    "\n",
    "    mask = tf.placeholder(tf.int32,\n",
    "                          (batch_size, num_timesteps))\n",
    "    keep_prob = tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "    global_step = tf.Variable(tf.zeros([], tf.int32),\n",
    "                              name = \"global_step\",\n",
    "                              trainable = False)\n",
    "    # prediction process:\n",
    "    # sentence: [a, b, c, d, e]\n",
    "    # input: [image, a, b, c, d]\n",
    "    # image_feature: [0.4, 0.3, 10, 2]\n",
    "    # predict #1: image_feature -> embedding_img -> lstm -> (a)\n",
    "    # predict #2: a -> embedding_word -> lstm -> (b)\n",
    "    # predict #3: b -> embedding_word -> lstm -> (c)\n",
    "    # ....\n",
    "\n",
    "    # Sets up embedding layer.\n",
    "    embedding_initializer = tf.random_uniform_initializer(-1.0, 1.0)\n",
    "    with tf.variable_scope('embeddings',\n",
    "                           initializer = embedding_initializer):\n",
    "        embeddings = tf.get_variable(\n",
    "            'embedding',\n",
    "            [vocab_size, hps.num_embedding_nodes],\n",
    "            tf.float32)\n",
    "        # embed_token_ids: [batch_size, num_timesteps - 1, num_embedding_nodes]\n",
    "        embed_token_ids = tf.nn.embedding_lookup(\n",
    "            embeddings,\n",
    "            sentence[:,0: num_timesteps - 1])\n",
    "        img_feature_embed_init = tf.uniform_unit_scaling_initializer(\n",
    "            factor = 1.0)\n",
    "        with tf.variable_scope('img_feature_embed',\n",
    "                               initializer = img_feature_embed_init):\n",
    "            # img_feature: [batch_size, img_feature_dim]\n",
    "            # embed_img: [batch_size, num_embedding_nodes]\n",
    "            embed_img = tf.layers.dense(img_feature, hps.num_embedding_nodes)\n",
    "            # embed_img: [batch_size, 1, num_embedding_nodes]\n",
    "            embed_img = tf.expand_dims(embed_img, 1)\n",
    "            #embed_inputs: [batch_size, num_timesteps, num_embedding_nodes]\n",
    "            embed_inputs = tf.concat([embed_img, embed_token_ids], axis = 1)\n",
    "\n",
    "        # Sets up rnn network\n",
    "        scale = 1.0 / math.sqrt(hps.num_embedding_nodes + hps.num_lstm_nodes[-1]) / 3.0\n",
    "        rnn_init = tf.random_uniform_initializer(-scale, scale)\n",
    "        with tf.variable_scope('lstm_nn', initializer = rnn_init):\n",
    "            cells = []\n",
    "            for i in range(hps.num_lstm_layers):\n",
    "                cell = create_rnn_cell(hps.num_lstm_nodes[i], hps.cell_type)\n",
    "                cell = dropout(cell, keep_prob)\n",
    "                cells.append(cell)\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "            init_state = cell.zero_state(hps.batch_size, tf.float32)\n",
    "            # rnn_outputs: [batch_size, num_timestep, hps.num_lstm_node[-1]]\n",
    "            rnn_outputs, _ = tf.nn.dynamic_rnn(cell,\n",
    "                                               embed_inputs,\n",
    "                                               initial_state = init_state)\n",
    "        # Sets up fully-connected layer\n",
    "        fc_init = tf.uniform_unit_scaling_initializer(factor = 1.0)\n",
    "        with tf.variable_scope('fc', initializer = fc_init):\n",
    "            rnn_outputs_2d = tf.reshape(rnn_outputs,\n",
    "                                        [-1, hps.num_lstm_nodes[-1]])\n",
    "            fc1  = tf.layers.dense(rnn_outputs_2d,\n",
    "                                  hps.num_fc_nodes,\n",
    "                                  name = \"fc1\")\n",
    "            fc1_dropout = tf.layers.dropout(fc1, keep_prob)\n",
    "            fc1_relu = tf.nn.relu(fc1_dropout)\n",
    "            logits = tf.layers.dense(fc1_relu,\n",
    "                                     vocab_size,\n",
    "                                     name = \"logits\")\n",
    "\n",
    "        # Calculates loss\n",
    "        with tf.variable_scope('loss'):\n",
    "            sentence_flatten = tf.reshape(sentence, [-1])\n",
    "            mask_flatten = tf.reshape(mask, [-1])\n",
    "            mask_sum = tf.reduce_sum(mask_flatten)\n",
    "            mask_flatten = tf.cast(mask_flatten, tf.float32)\n",
    "            mask_sum = tf.cast(mask_sum, tf.float32)\n",
    "\n",
    "            softmax_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits = logits,\n",
    "                labels = sentence_flatten)\n",
    "\n",
    "            weighted_softmax_loss = tf.multiply(\n",
    "                softmax_loss, tf.cast(mask_flatten, tf.float32))\n",
    "            loss = tf.reduce_sum(weighted_softmax_loss) / tf.cast(mask_sum, tf.float32)\n",
    "\n",
    "            prediction = tf.argmax(logits, 1, output_type = tf.int32)\n",
    "            correct_prediction = tf.equal(prediction,\n",
    "                                          sentence_flatten)\n",
    "            weighted_correct_prediction = tf.multiply(\n",
    "                tf.cast(correct_prediction, tf.float32),\n",
    "                tf.cast(mask_flatten, tf.float32))\n",
    "            print(prediction)\n",
    "            # predict_sentence = [vocab.id_to_word(each_sentence) for each_sentence in sentence]\n",
    "            # if global_step % 100 == 0:\n",
    "            #     print(predict_sentence)\n",
    "            accuracy = tf.reduce_sum(weighted_correct_prediction) / mask_sum\n",
    "            tf.summary.scalar('loss', loss)\n",
    "\n",
    "        # Defines train op.\n",
    "        with tf.variable_scope('train_op'):\n",
    "            tvars = tf.trainable_variables()\n",
    "            for var in tvars:\n",
    "                logging.info('variable name: %s' % var.name)\n",
    "                grads, _ = tf.clip_by_global_norm(\n",
    "                    tf.gradients(loss, tvars), hps.clip_lstm_grades)\n",
    "                optimizer = tf.train.AdamOptimizer(hps.learning_rate)\n",
    "                train_op = optimizer.apply_gradients(\n",
    "                    zip(grads, tvars),global_step = global_step)\n",
    "\n",
    "        return ((img_feature, sentence, mask, keep_prob),\n",
    "                (loss, accuracy, train_op),\n",
    "                global_step,prediction)\n",
    "\n",
    "place_holders, metrics, global_step, prediction = get_train_model(hps, vocab_size, img_feature_dim)\n",
    "img_feature, sentence, mask, keep_prob = place_holders\n",
    "loss, accuracy, train_op = metrics\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep = 10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step:    10, loss: 9.247, accu: 0.001\n",
      "INFO:tensorflow:Step:    20, loss: 8.957, accu: 0.000\n",
      "INFO:tensorflow:Step:    30, loss: 8.502, accu: 0.073\n",
      "INFO:tensorflow:Step:    40, loss: 8.027, accu: 0.059\n",
      "INFO:tensorflow:Step:    50, loss: 7.227, accu: 0.075\n",
      "INFO:tensorflow:Step:    60, loss: 6.424, accu: 0.111\n",
      "INFO:tensorflow:Step:    70, loss: 6.090, accu: 0.150\n",
      "INFO:tensorflow:Step:    80, loss: 5.837, accu: 0.143\n",
      "INFO:tensorflow:Step:    90, loss: 5.644, accu: 0.163\n",
      "INFO:tensorflow:Step:   100, loss: 5.795, accu: 0.147\n",
      "INFO:tensorflow:Step:   100, model saved\n",
      "A man a a a a a a a A\n",
      "INFO:tensorflow:Step:   110, loss: 5.805, accu: 0.131\n",
      "INFO:tensorflow:Step:   120, loss: 5.639, accu: 0.149\n",
      "INFO:tensorflow:Step:   130, loss: 5.434, accu: 0.164\n",
      "INFO:tensorflow:Step:   140, loss: 5.323, accu: 0.171\n",
      "INFO:tensorflow:Step:   150, loss: 5.555, accu: 0.167\n",
      "INFO:tensorflow:Step:   160, loss: 5.375, accu: 0.173\n",
      "INFO:tensorflow:Step:   170, loss: 5.539, accu: 0.162\n",
      "INFO:tensorflow:Step:   180, loss: 5.486, accu: 0.147\n",
      "INFO:tensorflow:Step:   190, loss: 5.248, accu: 0.169\n",
      "INFO:tensorflow:Step:   200, loss: 5.267, accu: 0.182\n",
      "INFO:tensorflow:Step:   200, model saved\n",
      "A man in a a a a a a A\n",
      "INFO:tensorflow:Step:   210, loss: 5.174, accu: 0.210\n",
      "INFO:tensorflow:Step:   220, loss: 5.162, accu: 0.192\n",
      "INFO:tensorflow:Step:   230, loss: 5.181, accu: 0.175\n",
      "INFO:tensorflow:Step:   240, loss: 5.054, accu: 0.191\n",
      "INFO:tensorflow:Step:   250, loss: 5.341, accu: 0.182\n",
      "INFO:tensorflow:Step:   260, loss: 5.099, accu: 0.186\n",
      "INFO:tensorflow:Step:   270, loss: 5.304, accu: 0.168\n",
      "INFO:tensorflow:Step:   280, loss: 5.033, accu: 0.199\n",
      "INFO:tensorflow:Step:   290, loss: 5.326, accu: 0.164\n",
      "INFO:tensorflow:Step:   300, loss: 5.085, accu: 0.186\n",
      "INFO:tensorflow:Step:   300, model saved\n",
      "A man in a a in . . a A\n",
      "INFO:tensorflow:Step:   310, loss: 4.951, accu: 0.188\n",
      "INFO:tensorflow:Step:   320, loss: 5.084, accu: 0.206\n",
      "INFO:tensorflow:Step:   330, loss: 5.084, accu: 0.199\n",
      "INFO:tensorflow:Step:   340, loss: 5.040, accu: 0.189\n",
      "INFO:tensorflow:Step:   350, loss: 5.196, accu: 0.179\n",
      "INFO:tensorflow:Step:   360, loss: 5.120, accu: 0.187\n",
      "INFO:tensorflow:Step:   370, loss: 4.992, accu: 0.184\n",
      "INFO:tensorflow:Step:   380, loss: 5.126, accu: 0.195\n",
      "INFO:tensorflow:Step:   390, loss: 5.314, accu: 0.187\n",
      "INFO:tensorflow:Step:   400, loss: 5.017, accu: 0.198\n",
      "INFO:tensorflow:Step:   400, model saved\n",
      "A man in in a a . . a A\n",
      "INFO:tensorflow:Step:   410, loss: 4.887, accu: 0.220\n",
      "INFO:tensorflow:Step:   420, loss: 5.012, accu: 0.215\n",
      "INFO:tensorflow:Step:   430, loss: 5.163, accu: 0.204\n",
      "INFO:tensorflow:Step:   440, loss: 5.007, accu: 0.190\n",
      "INFO:tensorflow:Step:   450, loss: 4.968, accu: 0.202\n",
      "INFO:tensorflow:Step:   460, loss: 4.945, accu: 0.227\n",
      "INFO:tensorflow:Step:   470, loss: 5.057, accu: 0.210\n",
      "INFO:tensorflow:Step:   480, loss: 4.936, accu: 0.222\n",
      "INFO:tensorflow:Step:   490, loss: 4.976, accu: 0.213\n",
      "INFO:tensorflow:Step:   500, loss: 4.933, accu: 0.235\n",
      "INFO:tensorflow:Step:   500, model saved\n",
      "A man in in in a is a a A\n",
      "INFO:tensorflow:Step:   510, loss: 4.722, accu: 0.237\n",
      "INFO:tensorflow:Step:   520, loss: 4.581, accu: 0.261\n",
      "INFO:tensorflow:Step:   530, loss: 4.762, accu: 0.247\n",
      "INFO:tensorflow:Step:   540, loss: 4.979, accu: 0.216\n",
      "INFO:tensorflow:Step:   550, loss: 4.851, accu: 0.220\n",
      "INFO:tensorflow:Step:   560, loss: 4.652, accu: 0.236\n",
      "INFO:tensorflow:Step:   570, loss: 4.496, accu: 0.230\n",
      "INFO:tensorflow:Step:   580, loss: 4.803, accu: 0.248\n",
      "INFO:tensorflow:Step:   590, loss: 4.547, accu: 0.248\n",
      "INFO:tensorflow:Step:   600, loss: 4.764, accu: 0.228\n",
      "INFO:tensorflow:Step:   600, model saved\n",
      "A men are a <UNK> on a shirt . A\n",
      "INFO:tensorflow:Step:   610, loss: 4.638, accu: 0.254\n",
      "INFO:tensorflow:Step:   620, loss: 4.754, accu: 0.230\n",
      "INFO:tensorflow:Step:   630, loss: 4.792, accu: 0.233\n",
      "INFO:tensorflow:Step:   640, loss: 4.677, accu: 0.256\n",
      "INFO:tensorflow:Step:   650, loss: 4.646, accu: 0.247\n",
      "INFO:tensorflow:Step:   660, loss: 4.757, accu: 0.252\n",
      "INFO:tensorflow:Step:   670, loss: 4.583, accu: 0.245\n",
      "INFO:tensorflow:Step:   680, loss: 4.661, accu: 0.253\n",
      "INFO:tensorflow:Step:   690, loss: 4.421, accu: 0.281\n",
      "INFO:tensorflow:Step:   700, loss: 4.676, accu: 0.233\n",
      "INFO:tensorflow:Step:   700, model saved\n",
      "A people men are in a street . . A\n",
      "INFO:tensorflow:Step:   710, loss: 4.222, accu: 0.260\n",
      "INFO:tensorflow:Step:   720, loss: 4.604, accu: 0.263\n",
      "INFO:tensorflow:Step:   730, loss: 4.566, accu: 0.247\n",
      "INFO:tensorflow:Step:   740, loss: 4.570, accu: 0.259\n",
      "INFO:tensorflow:Step:   750, loss: 4.460, accu: 0.256\n",
      "INFO:tensorflow:Step:   760, loss: 4.484, accu: 0.255\n",
      "INFO:tensorflow:Step:   770, loss: 4.634, accu: 0.256\n",
      "INFO:tensorflow:Step:   780, loss: 4.666, accu: 0.235\n",
      "INFO:tensorflow:Step:   790, loss: 4.461, accu: 0.267\n",
      "INFO:tensorflow:Step:   800, loss: 4.480, accu: 0.285\n",
      "INFO:tensorflow:Step:   800, model saved\n",
      "A man of are on a blue . . A\n",
      "INFO:tensorflow:Step:   810, loss: 4.365, accu: 0.264\n",
      "INFO:tensorflow:Step:   820, loss: 4.340, accu: 0.281\n",
      "INFO:tensorflow:Step:   830, loss: 4.329, accu: 0.266\n",
      "INFO:tensorflow:Step:   840, loss: 4.395, accu: 0.261\n",
      "INFO:tensorflow:Step:   850, loss: 4.581, accu: 0.246\n",
      "INFO:tensorflow:Step:   860, loss: 4.392, accu: 0.287\n",
      "INFO:tensorflow:Step:   870, loss: 4.435, accu: 0.294\n",
      "INFO:tensorflow:Step:   880, loss: 4.324, accu: 0.258\n",
      "INFO:tensorflow:Step:   890, loss: 4.442, accu: 0.258\n",
      "INFO:tensorflow:Step:   900, loss: 4.420, accu: 0.288\n",
      "INFO:tensorflow:Step:   900, model saved\n",
      "A man in a and in a street . A\n",
      "INFO:tensorflow:Step:   910, loss: 4.355, accu: 0.266\n",
      "INFO:tensorflow:Step:   920, loss: 4.465, accu: 0.249\n",
      "INFO:tensorflow:Step:   930, loss: 4.236, accu: 0.281\n",
      "INFO:tensorflow:Step:   940, loss: 4.332, accu: 0.284\n",
      "INFO:tensorflow:Step:   950, loss: 4.209, accu: 0.286\n",
      "INFO:tensorflow:Step:   960, loss: 4.201, accu: 0.282\n",
      "INFO:tensorflow:Step:   970, loss: 4.194, accu: 0.287\n",
      "INFO:tensorflow:Step:   980, loss: 4.363, accu: 0.271\n",
      "INFO:tensorflow:Step:   990, loss: 4.492, accu: 0.242\n",
      "INFO:tensorflow:Step:  1000, loss: 4.517, accu: 0.266\n",
      "INFO:tensorflow:Step:  1000, model saved\n",
      "A people are people black are in a a A\n",
      "INFO:tensorflow:Step:  1010, loss: 4.282, accu: 0.280\n",
      "INFO:tensorflow:Step:  1020, loss: 4.154, accu: 0.254\n",
      "INFO:tensorflow:Step:  1030, loss: 4.442, accu: 0.286\n",
      "INFO:tensorflow:Step:  1040, loss: 4.311, accu: 0.275\n",
      "INFO:tensorflow:Step:  1050, loss: 4.190, accu: 0.269\n",
      "INFO:tensorflow:Step:  1060, loss: 4.406, accu: 0.291\n",
      "INFO:tensorflow:Step:  1070, loss: 4.567, accu: 0.255\n",
      "INFO:tensorflow:Step:  1080, loss: 4.256, accu: 0.294\n",
      "INFO:tensorflow:Step:  1090, loss: 4.170, accu: 0.312\n",
      "INFO:tensorflow:Step:  1100, loss: 4.360, accu: 0.282\n",
      "INFO:tensorflow:Step:  1100, model saved\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\zyc\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "A men are a in a red . . A\n",
      "INFO:tensorflow:Step:  1110, loss: 4.258, accu: 0.282\n",
      "INFO:tensorflow:Step:  1120, loss: 4.265, accu: 0.261\n",
      "INFO:tensorflow:Step:  1130, loss: 4.329, accu: 0.276\n",
      "INFO:tensorflow:Step:  1140, loss: 4.345, accu: 0.257\n",
      "INFO:tensorflow:Step:  1150, loss: 4.221, accu: 0.289\n",
      "INFO:tensorflow:Step:  1160, loss: 4.381, accu: 0.262\n",
      "INFO:tensorflow:Step:  1170, loss: 4.410, accu: 0.254\n",
      "INFO:tensorflow:Step:  1180, loss: 4.472, accu: 0.274\n",
      "INFO:tensorflow:Step:  1190, loss: 4.199, accu: 0.278\n",
      "INFO:tensorflow:Step:  1200, loss: 4.191, accu: 0.269\n",
      "INFO:tensorflow:Step:  1200, model saved\n",
      "A man dog is a blue and in a A\n",
      "INFO:tensorflow:Step:  1210, loss: 4.211, accu: 0.258\n",
      "INFO:tensorflow:Step:  1220, loss: 4.319, accu: 0.269\n",
      "INFO:tensorflow:Step:  1230, loss: 4.141, accu: 0.285\n",
      "INFO:tensorflow:Step:  1240, loss: 4.339, accu: 0.285\n",
      "INFO:tensorflow:Step:  1250, loss: 4.059, accu: 0.272\n",
      "INFO:tensorflow:Step:  1260, loss: 4.475, accu: 0.251\n",
      "INFO:tensorflow:Step:  1270, loss: 4.255, accu: 0.286\n",
      "INFO:tensorflow:Step:  1280, loss: 4.273, accu: 0.262\n",
      "INFO:tensorflow:Step:  1290, loss: 4.277, accu: 0.290\n",
      "INFO:tensorflow:Step:  1300, loss: 4.053, accu: 0.316\n",
      "INFO:tensorflow:Step:  1300, model saved\n",
      "A man in a and a street . sitting A\n",
      "INFO:tensorflow:Step:  1310, loss: 3.889, accu: 0.316\n",
      "INFO:tensorflow:Step:  1320, loss: 4.139, accu: 0.279\n",
      "INFO:tensorflow:Step:  1330, loss: 4.166, accu: 0.314\n",
      "INFO:tensorflow:Step:  1340, loss: 4.179, accu: 0.305\n",
      "INFO:tensorflow:Step:  1350, loss: 4.238, accu: 0.270\n",
      "INFO:tensorflow:Step:  1360, loss: 4.302, accu: 0.283\n",
      "INFO:tensorflow:Step:  1370, loss: 4.299, accu: 0.266\n",
      "INFO:tensorflow:Step:  1380, loss: 4.220, accu: 0.276\n",
      "INFO:tensorflow:Step:  1390, loss: 3.908, accu: 0.302\n",
      "INFO:tensorflow:Step:  1400, loss: 4.166, accu: 0.292\n",
      "INFO:tensorflow:Step:  1400, model saved\n",
      "A man of people are a on on the A\n",
      "INFO:tensorflow:Step:  1410, loss: 4.289, accu: 0.274\n",
      "INFO:tensorflow:Step:  1420, loss: 4.323, accu: 0.265\n",
      "INFO:tensorflow:Step:  1430, loss: 4.121, accu: 0.295\n",
      "INFO:tensorflow:Step:  1440, loss: 4.103, accu: 0.279\n",
      "INFO:tensorflow:Step:  1450, loss: 4.144, accu: 0.281\n",
      "INFO:tensorflow:Step:  1460, loss: 4.085, accu: 0.305\n",
      "INFO:tensorflow:Step:  1470, loss: 4.104, accu: 0.307\n",
      "INFO:tensorflow:Step:  1480, loss: 4.132, accu: 0.296\n",
      "INFO:tensorflow:Step:  1490, loss: 4.161, accu: 0.288\n",
      "INFO:tensorflow:Step:  1500, loss: 3.944, accu: 0.303\n",
      "INFO:tensorflow:Step:  1500, model saved\n",
      "A man in standing on a <UNK> of a A\n",
      "INFO:tensorflow:Step:  1510, loss: 4.406, accu: 0.293\n",
      "INFO:tensorflow:Step:  1520, loss: 4.175, accu: 0.260\n",
      "INFO:tensorflow:Step:  1530, loss: 4.326, accu: 0.275\n",
      "INFO:tensorflow:Step:  1540, loss: 4.209, accu: 0.308\n",
      "INFO:tensorflow:Step:  1550, loss: 4.332, accu: 0.288\n",
      "INFO:tensorflow:Step:  1560, loss: 3.982, accu: 0.301\n",
      "INFO:tensorflow:Step:  1570, loss: 4.250, accu: 0.289\n",
      "INFO:tensorflow:Step:  1580, loss: 4.183, accu: 0.281\n",
      "INFO:tensorflow:Step:  1590, loss: 4.132, accu: 0.293\n",
      "INFO:tensorflow:Step:  1600, loss: 4.093, accu: 0.268\n",
      "INFO:tensorflow:Step:  1600, model saved\n",
      "A older man in a street in . . A\n",
      "INFO:tensorflow:Step:  1610, loss: 3.909, accu: 0.304\n",
      "INFO:tensorflow:Step:  1620, loss: 4.250, accu: 0.267\n",
      "INFO:tensorflow:Step:  1630, loss: 4.432, accu: 0.264\n",
      "INFO:tensorflow:Step:  1640, loss: 3.967, accu: 0.306\n",
      "INFO:tensorflow:Step:  1650, loss: 4.030, accu: 0.277\n",
      "INFO:tensorflow:Step:  1660, loss: 3.908, accu: 0.301\n",
      "INFO:tensorflow:Step:  1670, loss: 4.094, accu: 0.315\n",
      "INFO:tensorflow:Step:  1680, loss: 4.012, accu: 0.269\n",
      "INFO:tensorflow:Step:  1690, loss: 3.925, accu: 0.307\n",
      "INFO:tensorflow:Step:  1700, loss: 4.111, accu: 0.292\n",
      "INFO:tensorflow:Step:  1700, model saved\n",
      "A men are a are woman a and and A\n",
      "INFO:tensorflow:Step:  1710, loss: 4.273, accu: 0.266\n",
      "INFO:tensorflow:Step:  1720, loss: 4.023, accu: 0.274\n",
      "INFO:tensorflow:Step:  1730, loss: 3.842, accu: 0.311\n",
      "INFO:tensorflow:Step:  1740, loss: 4.049, accu: 0.282\n",
      "INFO:tensorflow:Step:  1750, loss: 4.084, accu: 0.299\n",
      "INFO:tensorflow:Step:  1760, loss: 4.016, accu: 0.293\n",
      "INFO:tensorflow:Step:  1770, loss: 3.899, accu: 0.322\n",
      "INFO:tensorflow:Step:  1780, loss: 3.995, accu: 0.294\n",
      "INFO:tensorflow:Step:  1790, loss: 4.202, accu: 0.265\n",
      "INFO:tensorflow:Step:  1800, loss: 4.160, accu: 0.295\n",
      "INFO:tensorflow:Step:  1800, model saved\n",
      "A man of people people are sitting in in A\n",
      "INFO:tensorflow:Step:  1810, loss: 4.273, accu: 0.261\n",
      "INFO:tensorflow:Step:  1820, loss: 4.175, accu: 0.304\n",
      "INFO:tensorflow:Step:  1830, loss: 4.059, accu: 0.283\n",
      "INFO:tensorflow:Step:  1840, loss: 4.072, accu: 0.303\n",
      "INFO:tensorflow:Step:  1850, loss: 4.077, accu: 0.284\n",
      "INFO:tensorflow:Step:  1860, loss: 4.167, accu: 0.298\n",
      "INFO:tensorflow:Step:  1870, loss: 4.229, accu: 0.295\n",
      "INFO:tensorflow:Step:  1880, loss: 4.065, accu: 0.320\n",
      "INFO:tensorflow:Step:  1890, loss: 4.179, accu: 0.279\n",
      "INFO:tensorflow:Step:  1900, loss: 4.106, accu: 0.304\n",
      "INFO:tensorflow:Step:  1900, model saved\n",
      "A people are a . a street . a A\n",
      "INFO:tensorflow:Step:  1910, loss: 4.022, accu: 0.286\n",
      "INFO:tensorflow:Step:  1920, loss: 3.863, accu: 0.305\n",
      "INFO:tensorflow:Step:  1930, loss: 3.832, accu: 0.314\n",
      "INFO:tensorflow:Step:  1940, loss: 4.116, accu: 0.278\n",
      "INFO:tensorflow:Step:  1950, loss: 4.061, accu: 0.277\n",
      "INFO:tensorflow:Step:  1960, loss: 3.828, accu: 0.324\n",
      "INFO:tensorflow:Step:  1970, loss: 3.951, accu: 0.311\n",
      "INFO:tensorflow:Step:  1980, loss: 4.052, accu: 0.296\n",
      "INFO:tensorflow:Step:  1990, loss: 4.106, accu: 0.303\n",
      "INFO:tensorflow:Step:  2000, loss: 3.951, accu: 0.310\n",
      "INFO:tensorflow:Step:  2000, model saved\n",
      "A man man is a in a <UNK> . A\n",
      "INFO:tensorflow:Step:  2010, loss: 3.954, accu: 0.295\n",
      "INFO:tensorflow:Step:  2020, loss: 4.112, accu: 0.298\n",
      "INFO:tensorflow:Step:  2030, loss: 4.029, accu: 0.308\n",
      "INFO:tensorflow:Step:  2040, loss: 3.748, accu: 0.319\n",
      "INFO:tensorflow:Step:  2050, loss: 4.246, accu: 0.280\n",
      "INFO:tensorflow:Step:  2060, loss: 4.185, accu: 0.268\n",
      "INFO:tensorflow:Step:  2070, loss: 3.996, accu: 0.304\n",
      "INFO:tensorflow:Step:  2080, loss: 3.833, accu: 0.320\n",
      "INFO:tensorflow:Step:  2090, loss: 4.166, accu: 0.283\n",
      "INFO:tensorflow:Step:  2100, loss: 4.038, accu: 0.299\n",
      "INFO:tensorflow:Step:  2100, model saved\n",
      "A man in on a a a a a A\n",
      "INFO:tensorflow:Step:  2110, loss: 4.158, accu: 0.299\n",
      "INFO:tensorflow:Step:  2120, loss: 4.011, accu: 0.307\n",
      "INFO:tensorflow:Step:  2130, loss: 4.164, accu: 0.289\n",
      "INFO:tensorflow:Step:  2140, loss: 3.812, accu: 0.311\n",
      "INFO:tensorflow:Step:  2150, loss: 4.017, accu: 0.303\n",
      "INFO:tensorflow:Step:  2160, loss: 4.123, accu: 0.280\n",
      "INFO:tensorflow:Step:  2170, loss: 3.996, accu: 0.296\n",
      "INFO:tensorflow:Step:  2180, loss: 3.885, accu: 0.322\n",
      "INFO:tensorflow:Step:  2190, loss: 3.937, accu: 0.297\n",
      "INFO:tensorflow:Step:  2200, loss: 4.067, accu: 0.285\n",
      "INFO:tensorflow:Step:  2200, model saved\n",
      "A men men young are sitting a the water A\n",
      "INFO:tensorflow:Step:  2210, loss: 3.973, accu: 0.299\n",
      "INFO:tensorflow:Step:  2220, loss: 3.915, accu: 0.315\n",
      "INFO:tensorflow:Step:  2230, loss: 3.856, accu: 0.331\n",
      "INFO:tensorflow:Step:  2240, loss: 3.934, accu: 0.315\n",
      "INFO:tensorflow:Step:  2250, loss: 3.963, accu: 0.314\n",
      "INFO:tensorflow:Step:  2260, loss: 3.966, accu: 0.306\n",
      "INFO:tensorflow:Step:  2270, loss: 3.984, accu: 0.307\n",
      "INFO:tensorflow:Step:  2280, loss: 3.555, accu: 0.349\n",
      "INFO:tensorflow:Step:  2290, loss: 4.113, accu: 0.306\n",
      "INFO:tensorflow:Step:  2300, loss: 4.233, accu: 0.269\n",
      "INFO:tensorflow:Step:  2300, model saved\n",
      "A man in standing a ball of a street A\n",
      "INFO:tensorflow:Step:  2310, loss: 4.056, accu: 0.308\n",
      "INFO:tensorflow:Step:  2320, loss: 3.955, accu: 0.316\n",
      "INFO:tensorflow:Step:  2330, loss: 3.843, accu: 0.316\n",
      "INFO:tensorflow:Step:  2340, loss: 3.915, accu: 0.309\n",
      "INFO:tensorflow:Step:  2350, loss: 3.917, accu: 0.292\n",
      "INFO:tensorflow:Step:  2360, loss: 3.849, accu: 0.305\n",
      "INFO:tensorflow:Step:  2370, loss: 4.072, accu: 0.318\n",
      "INFO:tensorflow:Step:  2380, loss: 3.870, accu: 0.331\n",
      "INFO:tensorflow:Step:  2390, loss: 3.851, accu: 0.318\n",
      "INFO:tensorflow:Step:  2400, loss: 3.717, accu: 0.327\n",
      "INFO:tensorflow:Step:  2400, model saved\n",
      "A men are a shirts are are one in A\n",
      "INFO:tensorflow:Step:  2410, loss: 3.972, accu: 0.310\n",
      "INFO:tensorflow:Step:  2420, loss: 3.988, accu: 0.299\n",
      "INFO:tensorflow:Step:  2430, loss: 4.063, accu: 0.296\n",
      "INFO:tensorflow:Step:  2440, loss: 4.024, accu: 0.286\n",
      "INFO:tensorflow:Step:  2450, loss: 3.808, accu: 0.319\n",
      "INFO:tensorflow:Step:  2460, loss: 3.902, accu: 0.321\n",
      "INFO:tensorflow:Step:  2470, loss: 4.008, accu: 0.311\n",
      "INFO:tensorflow:Step:  2480, loss: 3.964, accu: 0.291\n",
      "INFO:tensorflow:Step:  2490, loss: 3.908, accu: 0.302\n",
      "INFO:tensorflow:Step:  2500, loss: 3.857, accu: 0.301\n",
      "INFO:tensorflow:Step:  2500, model saved\n",
      "A are in in . a a . a A\n",
      "INFO:tensorflow:Step:  2510, loss: 3.823, accu: 0.329\n",
      "INFO:tensorflow:Step:  2520, loss: 3.868, accu: 0.313\n",
      "INFO:tensorflow:Step:  2530, loss: 4.111, accu: 0.314\n",
      "INFO:tensorflow:Step:  2540, loss: 4.055, accu: 0.280\n",
      "INFO:tensorflow:Step:  2550, loss: 4.043, accu: 0.282\n",
      "INFO:tensorflow:Step:  2560, loss: 3.907, accu: 0.326\n",
      "INFO:tensorflow:Step:  2570, loss: 3.864, accu: 0.290\n",
      "INFO:tensorflow:Step:  2580, loss: 3.896, accu: 0.324\n",
      "INFO:tensorflow:Step:  2590, loss: 4.159, accu: 0.277\n",
      "INFO:tensorflow:Step:  2600, loss: 3.782, accu: 0.307\n",
      "INFO:tensorflow:Step:  2600, model saved\n",
      "A man in a blue shirt is a shirt A\n",
      "INFO:tensorflow:Step:  2610, loss: 4.017, accu: 0.308\n",
      "INFO:tensorflow:Step:  2620, loss: 3.628, accu: 0.336\n",
      "INFO:tensorflow:Step:  2630, loss: 4.056, accu: 0.278\n",
      "INFO:tensorflow:Step:  2640, loss: 3.813, accu: 0.302\n",
      "INFO:tensorflow:Step:  2650, loss: 3.825, accu: 0.321\n",
      "INFO:tensorflow:Step:  2660, loss: 3.785, accu: 0.325\n",
      "INFO:tensorflow:Step:  2670, loss: 3.895, accu: 0.314\n",
      "INFO:tensorflow:Step:  2680, loss: 3.958, accu: 0.310\n",
      "INFO:tensorflow:Step:  2690, loss: 3.979, accu: 0.293\n",
      "INFO:tensorflow:Step:  2700, loss: 3.959, accu: 0.293\n",
      "INFO:tensorflow:Step:  2700, model saved\n",
      "A in on a in in a . . A\n",
      "INFO:tensorflow:Step:  2710, loss: 4.012, accu: 0.274\n",
      "INFO:tensorflow:Step:  2720, loss: 3.893, accu: 0.324\n",
      "INFO:tensorflow:Step:  2730, loss: 3.910, accu: 0.322\n",
      "INFO:tensorflow:Step:  2740, loss: 3.702, accu: 0.330\n",
      "INFO:tensorflow:Step:  2750, loss: 3.869, accu: 0.304\n",
      "INFO:tensorflow:Step:  2760, loss: 3.828, accu: 0.327\n",
      "INFO:tensorflow:Step:  2770, loss: 3.934, accu: 0.316\n",
      "INFO:tensorflow:Step:  2780, loss: 4.116, accu: 0.276\n",
      "INFO:tensorflow:Step:  2790, loss: 3.742, accu: 0.327\n",
      "INFO:tensorflow:Step:  2800, loss: 3.944, accu: 0.316\n",
      "INFO:tensorflow:Step:  2800, model saved\n",
      "A people are on a street . in a A\n",
      "INFO:tensorflow:Step:  2810, loss: 3.787, accu: 0.310\n",
      "INFO:tensorflow:Step:  2820, loss: 3.984, accu: 0.298\n",
      "INFO:tensorflow:Step:  2830, loss: 3.853, accu: 0.332\n",
      "INFO:tensorflow:Step:  2840, loss: 3.735, accu: 0.305\n",
      "INFO:tensorflow:Step:  2850, loss: 3.811, accu: 0.310\n",
      "INFO:tensorflow:Step:  2860, loss: 3.820, accu: 0.317\n",
      "INFO:tensorflow:Step:  2870, loss: 3.819, accu: 0.332\n",
      "INFO:tensorflow:Step:  2880, loss: 3.677, accu: 0.305\n",
      "INFO:tensorflow:Step:  2890, loss: 4.100, accu: 0.308\n",
      "INFO:tensorflow:Step:  2900, loss: 3.704, accu: 0.335\n",
      "INFO:tensorflow:Step:  2900, model saved\n",
      "A man in in a a a <UNK> . A\n",
      "INFO:tensorflow:Step:  2910, loss: 3.919, accu: 0.324\n",
      "INFO:tensorflow:Step:  2920, loss: 4.120, accu: 0.276\n",
      "INFO:tensorflow:Step:  2930, loss: 3.769, accu: 0.325\n",
      "INFO:tensorflow:Step:  2940, loss: 3.837, accu: 0.324\n",
      "INFO:tensorflow:Step:  2950, loss: 3.750, accu: 0.324\n",
      "INFO:tensorflow:Step:  2960, loss: 3.982, accu: 0.313\n",
      "INFO:tensorflow:Step:  2970, loss: 3.804, accu: 0.318\n",
      "INFO:tensorflow:Step:  2980, loss: 3.737, accu: 0.316\n",
      "INFO:tensorflow:Step:  2990, loss: 3.988, accu: 0.297\n",
      "INFO:tensorflow:Step:  3000, loss: 4.016, accu: 0.293\n",
      "INFO:tensorflow:Step:  3000, model saved\n",
      "A man dog is standing on a man dog A\n",
      "INFO:tensorflow:Step:  3010, loss: 3.728, accu: 0.312\n",
      "INFO:tensorflow:Step:  3020, loss: 4.169, accu: 0.291\n",
      "INFO:tensorflow:Step:  3030, loss: 3.769, accu: 0.340\n",
      "INFO:tensorflow:Step:  3040, loss: 3.852, accu: 0.319\n",
      "INFO:tensorflow:Step:  3050, loss: 3.790, accu: 0.330\n",
      "INFO:tensorflow:Step:  3060, loss: 3.831, accu: 0.314\n",
      "INFO:tensorflow:Step:  3070, loss: 3.775, accu: 0.333\n",
      "INFO:tensorflow:Step:  3080, loss: 3.716, accu: 0.322\n",
      "INFO:tensorflow:Step:  3090, loss: 3.981, accu: 0.290\n",
      "INFO:tensorflow:Step:  3100, loss: 4.041, accu: 0.273\n",
      "INFO:tensorflow:Step:  3100, model saved\n",
      "A older man in a red shirt is and A\n",
      "INFO:tensorflow:Step:  3110, loss: 3.940, accu: 0.310\n",
      "INFO:tensorflow:Step:  3120, loss: 3.857, accu: 0.342\n",
      "INFO:tensorflow:Step:  3130, loss: 3.736, accu: 0.329\n",
      "INFO:tensorflow:Step:  3140, loss: 3.479, accu: 0.330\n",
      "INFO:tensorflow:Step:  3150, loss: 3.698, accu: 0.309\n",
      "INFO:tensorflow:Step:  3160, loss: 3.814, accu: 0.324\n",
      "INFO:tensorflow:Step:  3170, loss: 3.687, accu: 0.327\n",
      "INFO:tensorflow:Step:  3180, loss: 3.834, accu: 0.314\n",
      "INFO:tensorflow:Step:  3190, loss: 3.834, accu: 0.325\n",
      "INFO:tensorflow:Step:  3200, loss: 3.870, accu: 0.318\n",
      "INFO:tensorflow:Step:  3200, model saved\n",
      "A man in a red shirt is to a A\n",
      "INFO:tensorflow:Step:  3210, loss: 3.841, accu: 0.325\n",
      "INFO:tensorflow:Step:  3220, loss: 3.708, accu: 0.351\n",
      "INFO:tensorflow:Step:  3230, loss: 3.684, accu: 0.343\n",
      "INFO:tensorflow:Step:  3240, loss: 3.657, accu: 0.350\n",
      "INFO:tensorflow:Step:  3250, loss: 3.942, accu: 0.308\n",
      "INFO:tensorflow:Step:  3260, loss: 3.835, accu: 0.312\n",
      "INFO:tensorflow:Step:  3270, loss: 3.950, accu: 0.293\n",
      "INFO:tensorflow:Step:  3280, loss: 3.788, accu: 0.325\n",
      "INFO:tensorflow:Step:  3290, loss: 3.745, accu: 0.322\n",
      "INFO:tensorflow:Step:  3300, loss: 4.023, accu: 0.307\n",
      "INFO:tensorflow:Step:  3300, model saved\n",
      "A young in at a <UNK> . . a A\n",
      "INFO:tensorflow:Step:  3310, loss: 4.019, accu: 0.293\n",
      "INFO:tensorflow:Step:  3320, loss: 3.912, accu: 0.318\n",
      "INFO:tensorflow:Step:  3330, loss: 3.760, accu: 0.319\n",
      "INFO:tensorflow:Step:  3340, loss: 3.924, accu: 0.319\n",
      "INFO:tensorflow:Step:  3350, loss: 3.809, accu: 0.325\n",
      "INFO:tensorflow:Step:  3360, loss: 3.927, accu: 0.323\n",
      "INFO:tensorflow:Step:  3370, loss: 3.944, accu: 0.284\n",
      "INFO:tensorflow:Step:  3380, loss: 3.893, accu: 0.291\n",
      "INFO:tensorflow:Step:  3390, loss: 3.701, accu: 0.311\n",
      "INFO:tensorflow:Step:  3400, loss: 3.449, accu: 0.362\n",
      "INFO:tensorflow:Step:  3400, model saved\n",
      "A man in a are a and . a A\n",
      "INFO:tensorflow:Step:  3410, loss: 3.815, accu: 0.311\n",
      "INFO:tensorflow:Step:  3420, loss: 3.757, accu: 0.327\n",
      "INFO:tensorflow:Step:  3430, loss: 3.822, accu: 0.304\n",
      "INFO:tensorflow:Step:  3440, loss: 3.662, accu: 0.339\n",
      "INFO:tensorflow:Step:  3450, loss: 4.002, accu: 0.301\n",
      "INFO:tensorflow:Step:  3460, loss: 3.688, accu: 0.342\n",
      "INFO:tensorflow:Step:  3470, loss: 3.773, accu: 0.305\n",
      "INFO:tensorflow:Step:  3480, loss: 3.815, accu: 0.315\n",
      "INFO:tensorflow:Step:  3490, loss: 3.822, accu: 0.311\n",
      "INFO:tensorflow:Step:  3500, loss: 3.769, accu: 0.315\n",
      "INFO:tensorflow:Step:  3500, model saved\n",
      "A group in in in in a woman girl A\n",
      "INFO:tensorflow:Step:  3510, loss: 3.673, accu: 0.328\n",
      "INFO:tensorflow:Step:  3520, loss: 3.932, accu: 0.303\n",
      "INFO:tensorflow:Step:  3530, loss: 3.790, accu: 0.333\n",
      "INFO:tensorflow:Step:  3540, loss: 4.062, accu: 0.323\n",
      "INFO:tensorflow:Step:  3550, loss: 3.934, accu: 0.305\n",
      "INFO:tensorflow:Step:  3560, loss: 3.810, accu: 0.320\n",
      "INFO:tensorflow:Step:  3570, loss: 4.097, accu: 0.302\n",
      "INFO:tensorflow:Step:  3580, loss: 3.765, accu: 0.326\n",
      "INFO:tensorflow:Step:  3590, loss: 3.563, accu: 0.338\n",
      "INFO:tensorflow:Step:  3600, loss: 3.963, accu: 0.324\n",
      "INFO:tensorflow:Step:  3600, model saved\n",
      "A men are on a street field . a A\n",
      "INFO:tensorflow:Step:  3610, loss: 3.989, accu: 0.327\n",
      "INFO:tensorflow:Step:  3620, loss: 3.590, accu: 0.320\n",
      "INFO:tensorflow:Step:  3630, loss: 3.739, accu: 0.347\n",
      "INFO:tensorflow:Step:  3640, loss: 3.803, accu: 0.300\n",
      "INFO:tensorflow:Step:  3650, loss: 3.779, accu: 0.338\n",
      "INFO:tensorflow:Step:  3660, loss: 3.794, accu: 0.344\n",
      "INFO:tensorflow:Step:  3670, loss: 3.904, accu: 0.304\n",
      "INFO:tensorflow:Step:  3680, loss: 3.916, accu: 0.301\n",
      "INFO:tensorflow:Step:  3690, loss: 3.614, accu: 0.336\n",
      "INFO:tensorflow:Step:  3700, loss: 3.837, accu: 0.321\n",
      "INFO:tensorflow:Step:  3700, model saved\n",
      "A young are in a a a . . A\n",
      "INFO:tensorflow:Step:  3710, loss: 3.608, accu: 0.351\n",
      "INFO:tensorflow:Step:  3720, loss: 3.629, accu: 0.379\n",
      "INFO:tensorflow:Step:  3730, loss: 3.850, accu: 0.343\n",
      "INFO:tensorflow:Step:  3740, loss: 3.971, accu: 0.317\n",
      "INFO:tensorflow:Step:  3750, loss: 3.851, accu: 0.305\n",
      "INFO:tensorflow:Step:  3760, loss: 3.857, accu: 0.314\n",
      "INFO:tensorflow:Step:  3770, loss: 3.613, accu: 0.332\n",
      "INFO:tensorflow:Step:  3780, loss: 3.692, accu: 0.349\n",
      "INFO:tensorflow:Step:  3790, loss: 3.696, accu: 0.299\n",
      "INFO:tensorflow:Step:  3800, loss: 3.909, accu: 0.295\n",
      "INFO:tensorflow:Step:  3800, model saved\n",
      "A are a are a a . one . A\n",
      "INFO:tensorflow:Step:  3810, loss: 3.951, accu: 0.326\n",
      "INFO:tensorflow:Step:  3820, loss: 3.712, accu: 0.317\n",
      "INFO:tensorflow:Step:  3830, loss: 3.611, accu: 0.340\n",
      "INFO:tensorflow:Step:  3840, loss: 3.671, accu: 0.348\n",
      "INFO:tensorflow:Step:  3850, loss: 3.434, accu: 0.365\n",
      "INFO:tensorflow:Step:  3860, loss: 3.707, accu: 0.343\n",
      "INFO:tensorflow:Step:  3870, loss: 3.858, accu: 0.309\n",
      "INFO:tensorflow:Step:  3880, loss: 3.839, accu: 0.315\n",
      "INFO:tensorflow:Step:  3890, loss: 3.557, accu: 0.362\n",
      "INFO:tensorflow:Step:  3900, loss: 3.817, accu: 0.327\n",
      "INFO:tensorflow:Step:  3900, model saved\n",
      "A in a a table . . . . A\n",
      "INFO:tensorflow:Step:  3910, loss: 3.917, accu: 0.327\n",
      "INFO:tensorflow:Step:  3920, loss: 3.711, accu: 0.325\n",
      "INFO:tensorflow:Step:  3930, loss: 3.774, accu: 0.349\n",
      "INFO:tensorflow:Step:  3940, loss: 3.891, accu: 0.307\n",
      "INFO:tensorflow:Step:  3950, loss: 3.795, accu: 0.327\n",
      "INFO:tensorflow:Step:  3960, loss: 4.058, accu: 0.296\n",
      "INFO:tensorflow:Step:  3970, loss: 3.830, accu: 0.323\n",
      "INFO:tensorflow:Step:  3980, loss: 3.754, accu: 0.324\n",
      "INFO:tensorflow:Step:  3990, loss: 3.611, accu: 0.356\n",
      "INFO:tensorflow:Step:  4000, loss: 3.673, accu: 0.325\n",
      "INFO:tensorflow:Step:  4000, model saved\n",
      "A man in a a of a red in A\n",
      "INFO:tensorflow:Step:  4010, loss: 3.434, accu: 0.359\n",
      "INFO:tensorflow:Step:  4020, loss: 3.922, accu: 0.301\n",
      "INFO:tensorflow:Step:  4030, loss: 3.710, accu: 0.365\n",
      "INFO:tensorflow:Step:  4040, loss: 3.587, accu: 0.344\n",
      "INFO:tensorflow:Step:  4050, loss: 3.706, accu: 0.337\n",
      "INFO:tensorflow:Step:  4060, loss: 3.752, accu: 0.337\n",
      "INFO:tensorflow:Step:  4070, loss: 3.881, accu: 0.317\n",
      "INFO:tensorflow:Step:  4080, loss: 3.821, accu: 0.314\n",
      "INFO:tensorflow:Step:  4090, loss: 3.797, accu: 0.338\n",
      "INFO:tensorflow:Step:  4100, loss: 3.623, accu: 0.326\n",
      "INFO:tensorflow:Step:  4100, model saved\n",
      "A man in a pants is a in a A\n",
      "INFO:tensorflow:Step:  4110, loss: 3.840, accu: 0.322\n",
      "INFO:tensorflow:Step:  4120, loss: 3.664, accu: 0.332\n",
      "INFO:tensorflow:Step:  4130, loss: 3.696, accu: 0.313\n",
      "INFO:tensorflow:Step:  4140, loss: 3.920, accu: 0.328\n",
      "INFO:tensorflow:Step:  4150, loss: 3.784, accu: 0.326\n",
      "INFO:tensorflow:Step:  4160, loss: 3.660, accu: 0.329\n",
      "INFO:tensorflow:Step:  4170, loss: 3.772, accu: 0.326\n",
      "INFO:tensorflow:Step:  4180, loss: 3.954, accu: 0.305\n",
      "INFO:tensorflow:Step:  4190, loss: 3.826, accu: 0.303\n",
      "INFO:tensorflow:Step:  4200, loss: 3.564, accu: 0.360\n",
      "INFO:tensorflow:Step:  4200, model saved\n",
      "A in of a air of a is playing A\n",
      "INFO:tensorflow:Step:  4210, loss: 3.629, accu: 0.329\n",
      "INFO:tensorflow:Step:  4220, loss: 3.758, accu: 0.315\n",
      "INFO:tensorflow:Step:  4230, loss: 3.418, accu: 0.362\n",
      "INFO:tensorflow:Step:  4240, loss: 3.555, accu: 0.355\n",
      "INFO:tensorflow:Step:  4250, loss: 3.727, accu: 0.327\n",
      "INFO:tensorflow:Step:  4260, loss: 3.881, accu: 0.289\n",
      "INFO:tensorflow:Step:  4270, loss: 3.660, accu: 0.340\n",
      "INFO:tensorflow:Step:  4280, loss: 3.762, accu: 0.317\n",
      "INFO:tensorflow:Step:  4290, loss: 3.762, accu: 0.338\n",
      "INFO:tensorflow:Step:  4300, loss: 3.707, accu: 0.344\n",
      "INFO:tensorflow:Step:  4300, model saved\n",
      "A man is standing a bike in a street A\n",
      "INFO:tensorflow:Step:  4310, loss: 3.999, accu: 0.300\n",
      "INFO:tensorflow:Step:  4320, loss: 3.846, accu: 0.307\n",
      "INFO:tensorflow:Step:  4330, loss: 3.938, accu: 0.326\n",
      "INFO:tensorflow:Step:  4340, loss: 3.549, accu: 0.335\n",
      "INFO:tensorflow:Step:  4350, loss: 3.581, accu: 0.357\n",
      "INFO:tensorflow:Step:  4360, loss: 3.702, accu: 0.356\n",
      "INFO:tensorflow:Step:  4370, loss: 4.034, accu: 0.310\n",
      "INFO:tensorflow:Step:  4380, loss: 3.830, accu: 0.320\n",
      "INFO:tensorflow:Step:  4390, loss: 3.515, accu: 0.353\n",
      "INFO:tensorflow:Step:  4400, loss: 3.670, accu: 0.330\n",
      "INFO:tensorflow:Step:  4400, model saved\n",
      "A a man street in a man in a A\n",
      "INFO:tensorflow:Step:  4410, loss: 3.816, accu: 0.322\n",
      "INFO:tensorflow:Step:  4420, loss: 3.820, accu: 0.311\n",
      "INFO:tensorflow:Step:  4430, loss: 3.695, accu: 0.338\n",
      "INFO:tensorflow:Step:  4440, loss: 3.518, accu: 0.357\n",
      "INFO:tensorflow:Step:  4450, loss: 3.867, accu: 0.329\n",
      "INFO:tensorflow:Step:  4460, loss: 3.958, accu: 0.312\n",
      "INFO:tensorflow:Step:  4470, loss: 3.652, accu: 0.339\n",
      "INFO:tensorflow:Step:  4480, loss: 3.573, accu: 0.357\n",
      "INFO:tensorflow:Step:  4490, loss: 3.705, accu: 0.329\n",
      "INFO:tensorflow:Step:  4500, loss: 3.880, accu: 0.312\n",
      "INFO:tensorflow:Step:  4500, model saved\n",
      "A man in a red is hair in . A\n",
      "INFO:tensorflow:Step:  4510, loss: 3.773, accu: 0.309\n",
      "INFO:tensorflow:Step:  4520, loss: 3.735, accu: 0.332\n",
      "INFO:tensorflow:Step:  4530, loss: 4.021, accu: 0.302\n",
      "INFO:tensorflow:Step:  4540, loss: 3.611, accu: 0.345\n",
      "INFO:tensorflow:Step:  4550, loss: 3.628, accu: 0.325\n",
      "INFO:tensorflow:Step:  4560, loss: 3.919, accu: 0.312\n",
      "INFO:tensorflow:Step:  4570, loss: 3.729, accu: 0.331\n",
      "INFO:tensorflow:Step:  4580, loss: 3.878, accu: 0.304\n",
      "INFO:tensorflow:Step:  4590, loss: 3.726, accu: 0.326\n",
      "INFO:tensorflow:Step:  4600, loss: 3.661, accu: 0.333\n",
      "INFO:tensorflow:Step:  4600, model saved\n",
      "A man in a white shirt is standing at A\n",
      "INFO:tensorflow:Step:  4610, loss: 3.704, accu: 0.328\n",
      "INFO:tensorflow:Step:  4620, loss: 3.634, accu: 0.339\n",
      "INFO:tensorflow:Step:  4630, loss: 3.395, accu: 0.368\n",
      "INFO:tensorflow:Step:  4640, loss: 3.567, accu: 0.364\n",
      "INFO:tensorflow:Step:  4650, loss: 3.636, accu: 0.321\n",
      "INFO:tensorflow:Step:  4660, loss: 3.576, accu: 0.351\n",
      "INFO:tensorflow:Step:  4670, loss: 3.629, accu: 0.345\n",
      "INFO:tensorflow:Step:  4680, loss: 3.785, accu: 0.300\n",
      "INFO:tensorflow:Step:  4690, loss: 3.856, accu: 0.314\n",
      "INFO:tensorflow:Step:  4700, loss: 3.667, accu: 0.343\n",
      "INFO:tensorflow:Step:  4700, model saved\n",
      "A in a hair and on a . . A\n",
      "INFO:tensorflow:Step:  4710, loss: 3.826, accu: 0.334\n",
      "INFO:tensorflow:Step:  4720, loss: 3.780, accu: 0.303\n",
      "INFO:tensorflow:Step:  4730, loss: 3.613, accu: 0.344\n",
      "INFO:tensorflow:Step:  4740, loss: 3.659, accu: 0.347\n",
      "INFO:tensorflow:Step:  4750, loss: 3.752, accu: 0.308\n",
      "INFO:tensorflow:Step:  4760, loss: 3.586, accu: 0.330\n",
      "INFO:tensorflow:Step:  4770, loss: 3.718, accu: 0.359\n",
      "INFO:tensorflow:Step:  4780, loss: 3.978, accu: 0.327\n",
      "INFO:tensorflow:Step:  4790, loss: 3.652, accu: 0.317\n",
      "INFO:tensorflow:Step:  4800, loss: 3.637, accu: 0.358\n",
      "INFO:tensorflow:Step:  4800, model saved\n",
      "A man is a and a bike bike . A\n",
      "INFO:tensorflow:Step:  4810, loss: 3.885, accu: 0.306\n",
      "INFO:tensorflow:Step:  4820, loss: 3.311, accu: 0.379\n",
      "INFO:tensorflow:Step:  4830, loss: 3.467, accu: 0.352\n",
      "INFO:tensorflow:Step:  4840, loss: 3.683, accu: 0.345\n",
      "INFO:tensorflow:Step:  4850, loss: 3.720, accu: 0.318\n",
      "INFO:tensorflow:Step:  4860, loss: 3.689, accu: 0.337\n",
      "INFO:tensorflow:Step:  4870, loss: 3.685, accu: 0.340\n",
      "INFO:tensorflow:Step:  4880, loss: 3.654, accu: 0.342\n",
      "INFO:tensorflow:Step:  4890, loss: 3.542, accu: 0.343\n",
      "INFO:tensorflow:Step:  4900, loss: 3.613, accu: 0.345\n",
      "INFO:tensorflow:Step:  4900, model saved\n",
      "A men men are on a . a a A\n",
      "INFO:tensorflow:Step:  4910, loss: 3.612, accu: 0.342\n",
      "INFO:tensorflow:Step:  4920, loss: 3.501, accu: 0.348\n",
      "INFO:tensorflow:Step:  4930, loss: 3.862, accu: 0.306\n",
      "INFO:tensorflow:Step:  4940, loss: 3.598, accu: 0.334\n",
      "INFO:tensorflow:Step:  4950, loss: 3.665, accu: 0.352\n",
      "INFO:tensorflow:Step:  4960, loss: 3.735, accu: 0.322\n",
      "INFO:tensorflow:Step:  4970, loss: 3.577, accu: 0.357\n",
      "INFO:tensorflow:Step:  4980, loss: 3.526, accu: 0.347\n",
      "INFO:tensorflow:Step:  4990, loss: 3.429, accu: 0.368\n",
      "INFO:tensorflow:Step:  5000, loss: 3.590, accu: 0.333\n",
      "INFO:tensorflow:Step:  5000, model saved\n",
      "A men are on at a table . . A\n",
      "INFO:tensorflow:Step:  5010, loss: 3.639, accu: 0.325\n",
      "INFO:tensorflow:Step:  5020, loss: 3.606, accu: 0.355\n",
      "INFO:tensorflow:Step:  5030, loss: 3.721, accu: 0.313\n",
      "INFO:tensorflow:Step:  5040, loss: 3.484, accu: 0.337\n",
      "INFO:tensorflow:Step:  5050, loss: 3.648, accu: 0.320\n",
      "INFO:tensorflow:Step:  5060, loss: 3.548, accu: 0.336\n",
      "INFO:tensorflow:Step:  5070, loss: 3.830, accu: 0.315\n",
      "INFO:tensorflow:Step:  5080, loss: 3.663, accu: 0.335\n",
      "INFO:tensorflow:Step:  5090, loss: 3.676, accu: 0.335\n",
      "INFO:tensorflow:Step:  5100, loss: 3.853, accu: 0.315\n",
      "INFO:tensorflow:Step:  5100, model saved\n",
      "A man are a street street . a a A\n",
      "INFO:tensorflow:Step:  5110, loss: 3.480, accu: 0.360\n",
      "INFO:tensorflow:Step:  5120, loss: 3.733, accu: 0.302\n",
      "INFO:tensorflow:Step:  5130, loss: 3.698, accu: 0.329\n",
      "INFO:tensorflow:Step:  5140, loss: 3.577, accu: 0.348\n",
      "INFO:tensorflow:Step:  5150, loss: 3.927, accu: 0.303\n",
      "INFO:tensorflow:Step:  5160, loss: 3.575, accu: 0.341\n",
      "INFO:tensorflow:Step:  5170, loss: 3.717, accu: 0.307\n",
      "INFO:tensorflow:Step:  5180, loss: 3.575, accu: 0.334\n",
      "INFO:tensorflow:Step:  5190, loss: 3.857, accu: 0.310\n",
      "INFO:tensorflow:Step:  5200, loss: 3.693, accu: 0.334\n",
      "INFO:tensorflow:Step:  5200, model saved\n",
      "A man in sitting a picture on a . A\n",
      "INFO:tensorflow:Step:  5210, loss: 3.871, accu: 0.296\n",
      "INFO:tensorflow:Step:  5220, loss: 3.521, accu: 0.359\n",
      "INFO:tensorflow:Step:  5230, loss: 3.609, accu: 0.330\n",
      "INFO:tensorflow:Step:  5240, loss: 3.363, accu: 0.343\n",
      "INFO:tensorflow:Step:  5250, loss: 3.662, accu: 0.338\n",
      "INFO:tensorflow:Step:  5260, loss: 3.901, accu: 0.316\n",
      "INFO:tensorflow:Step:  5270, loss: 3.796, accu: 0.319\n",
      "INFO:tensorflow:Step:  5280, loss: 3.587, accu: 0.321\n",
      "INFO:tensorflow:Step:  5290, loss: 3.638, accu: 0.348\n",
      "INFO:tensorflow:Step:  5300, loss: 3.517, accu: 0.346\n",
      "INFO:tensorflow:Step:  5300, model saved\n",
      "A are a a street street . a are A\n",
      "INFO:tensorflow:Step:  5310, loss: 3.863, accu: 0.306\n",
      "INFO:tensorflow:Step:  5320, loss: 3.752, accu: 0.352\n",
      "INFO:tensorflow:Step:  5330, loss: 3.816, accu: 0.317\n",
      "INFO:tensorflow:Step:  5340, loss: 3.374, accu: 0.356\n",
      "INFO:tensorflow:Step:  5350, loss: 3.796, accu: 0.340\n",
      "INFO:tensorflow:Step:  5360, loss: 3.487, accu: 0.343\n",
      "INFO:tensorflow:Step:  5370, loss: 3.681, accu: 0.308\n",
      "INFO:tensorflow:Step:  5380, loss: 3.597, accu: 0.328\n",
      "INFO:tensorflow:Step:  5390, loss: 3.882, accu: 0.312\n",
      "INFO:tensorflow:Step:  5400, loss: 3.892, accu: 0.307\n",
      "INFO:tensorflow:Step:  5400, model saved\n",
      "A young girl in in a and sitting with A\n",
      "INFO:tensorflow:Step:  5410, loss: 3.563, accu: 0.342\n",
      "INFO:tensorflow:Step:  5420, loss: 3.853, accu: 0.315\n",
      "INFO:tensorflow:Step:  5430, loss: 3.438, accu: 0.356\n",
      "INFO:tensorflow:Step:  5440, loss: 3.580, accu: 0.345\n",
      "INFO:tensorflow:Step:  5450, loss: 3.580, accu: 0.339\n",
      "INFO:tensorflow:Step:  5460, loss: 3.787, accu: 0.319\n",
      "INFO:tensorflow:Step:  5470, loss: 3.652, accu: 0.349\n",
      "INFO:tensorflow:Step:  5480, loss: 3.621, accu: 0.349\n",
      "INFO:tensorflow:Step:  5490, loss: 3.557, accu: 0.341\n",
      "INFO:tensorflow:Step:  5500, loss: 3.701, accu: 0.337\n",
      "INFO:tensorflow:Step:  5500, model saved\n",
      "A men in a and are on a field A\n",
      "INFO:tensorflow:Step:  5510, loss: 3.747, accu: 0.337\n",
      "INFO:tensorflow:Step:  5520, loss: 3.455, accu: 0.356\n",
      "INFO:tensorflow:Step:  5530, loss: 3.574, accu: 0.355\n",
      "INFO:tensorflow:Step:  5540, loss: 3.645, accu: 0.322\n",
      "INFO:tensorflow:Step:  5550, loss: 3.393, accu: 0.352\n",
      "INFO:tensorflow:Step:  5560, loss: 3.765, accu: 0.344\n",
      "INFO:tensorflow:Step:  5570, loss: 3.801, accu: 0.312\n",
      "INFO:tensorflow:Step:  5580, loss: 3.702, accu: 0.329\n",
      "INFO:tensorflow:Step:  5590, loss: 3.672, accu: 0.336\n",
      "INFO:tensorflow:Step:  5600, loss: 3.752, accu: 0.313\n",
      "INFO:tensorflow:Step:  5600, model saved\n",
      "A people are standing on a table . a A\n",
      "INFO:tensorflow:Step:  5610, loss: 3.750, accu: 0.334\n",
      "INFO:tensorflow:Step:  5620, loss: 3.502, accu: 0.351\n",
      "INFO:tensorflow:Step:  5630, loss: 3.697, accu: 0.346\n",
      "INFO:tensorflow:Step:  5640, loss: 3.743, accu: 0.332\n",
      "INFO:tensorflow:Step:  5650, loss: 3.626, accu: 0.352\n",
      "INFO:tensorflow:Step:  5660, loss: 3.514, accu: 0.345\n",
      "INFO:tensorflow:Step:  5670, loss: 3.785, accu: 0.314\n",
      "INFO:tensorflow:Step:  5680, loss: 3.695, accu: 0.317\n",
      "INFO:tensorflow:Step:  5690, loss: 3.754, accu: 0.330\n",
      "INFO:tensorflow:Step:  5700, loss: 3.448, accu: 0.335\n",
      "INFO:tensorflow:Step:  5700, model saved\n",
      "A man is is standing down to a man A\n",
      "INFO:tensorflow:Step:  5710, loss: 3.528, accu: 0.329\n",
      "INFO:tensorflow:Step:  5720, loss: 3.803, accu: 0.327\n",
      "INFO:tensorflow:Step:  5730, loss: 3.827, accu: 0.328\n",
      "INFO:tensorflow:Step:  5740, loss: 3.482, accu: 0.373\n",
      "INFO:tensorflow:Step:  5750, loss: 3.770, accu: 0.338\n",
      "INFO:tensorflow:Step:  5760, loss: 3.426, accu: 0.322\n",
      "INFO:tensorflow:Step:  5770, loss: 3.590, accu: 0.348\n",
      "INFO:tensorflow:Step:  5780, loss: 3.632, accu: 0.350\n",
      "INFO:tensorflow:Step:  5790, loss: 3.480, accu: 0.346\n",
      "INFO:tensorflow:Step:  5800, loss: 3.562, accu: 0.342\n",
      "INFO:tensorflow:Step:  5800, model saved\n",
      "A in a street street . . . . A\n",
      "INFO:tensorflow:Step:  5810, loss: 3.362, accu: 0.379\n",
      "INFO:tensorflow:Step:  5820, loss: 3.757, accu: 0.338\n",
      "INFO:tensorflow:Step:  5830, loss: 3.729, accu: 0.329\n",
      "INFO:tensorflow:Step:  5840, loss: 3.606, accu: 0.343\n",
      "INFO:tensorflow:Step:  5850, loss: 3.808, accu: 0.314\n",
      "INFO:tensorflow:Step:  5860, loss: 3.537, accu: 0.354\n",
      "INFO:tensorflow:Step:  5870, loss: 3.690, accu: 0.344\n",
      "INFO:tensorflow:Step:  5880, loss: 3.422, accu: 0.358\n",
      "INFO:tensorflow:Step:  5890, loss: 3.747, accu: 0.335\n",
      "INFO:tensorflow:Step:  5900, loss: 3.703, accu: 0.331\n",
      "INFO:tensorflow:Step:  5900, model saved\n",
      "A man of people are are a uniforms . A\n",
      "INFO:tensorflow:Step:  5910, loss: 3.660, accu: 0.318\n",
      "INFO:tensorflow:Step:  5920, loss: 3.818, accu: 0.314\n",
      "INFO:tensorflow:Step:  5930, loss: 3.924, accu: 0.316\n",
      "INFO:tensorflow:Step:  5940, loss: 3.725, accu: 0.304\n",
      "INFO:tensorflow:Step:  5950, loss: 3.481, accu: 0.375\n",
      "INFO:tensorflow:Step:  5960, loss: 3.688, accu: 0.359\n",
      "INFO:tensorflow:Step:  5970, loss: 3.440, accu: 0.350\n",
      "INFO:tensorflow:Step:  5980, loss: 3.837, accu: 0.304\n",
      "INFO:tensorflow:Step:  5990, loss: 3.481, accu: 0.339\n",
      "INFO:tensorflow:Step:  6000, loss: 3.829, accu: 0.302\n",
      "INFO:tensorflow:Step:  6000, model saved\n",
      "A group people are on a of a large A\n",
      "INFO:tensorflow:Step:  6010, loss: 3.585, accu: 0.320\n",
      "INFO:tensorflow:Step:  6020, loss: 3.665, accu: 0.334\n",
      "INFO:tensorflow:Step:  6030, loss: 3.753, accu: 0.347\n",
      "INFO:tensorflow:Step:  6040, loss: 3.834, accu: 0.315\n",
      "INFO:tensorflow:Step:  6050, loss: 3.643, accu: 0.365\n",
      "INFO:tensorflow:Step:  6060, loss: 3.533, accu: 0.336\n",
      "INFO:tensorflow:Step:  6070, loss: 3.562, accu: 0.366\n",
      "INFO:tensorflow:Step:  6080, loss: 3.626, accu: 0.365\n",
      "INFO:tensorflow:Step:  6090, loss: 3.441, accu: 0.351\n",
      "INFO:tensorflow:Step:  6100, loss: 3.490, accu: 0.369\n",
      "INFO:tensorflow:Step:  6100, model saved\n",
      "A men are a white room room . . A\n",
      "INFO:tensorflow:Step:  6110, loss: 3.769, accu: 0.291\n",
      "INFO:tensorflow:Step:  6120, loss: 3.634, accu: 0.339\n",
      "INFO:tensorflow:Step:  6130, loss: 3.484, accu: 0.357\n",
      "INFO:tensorflow:Step:  6140, loss: 3.544, accu: 0.323\n",
      "INFO:tensorflow:Step:  6150, loss: 3.788, accu: 0.350\n",
      "INFO:tensorflow:Step:  6160, loss: 3.608, accu: 0.343\n",
      "INFO:tensorflow:Step:  6170, loss: 3.544, accu: 0.365\n",
      "INFO:tensorflow:Step:  6180, loss: 3.831, accu: 0.321\n",
      "INFO:tensorflow:Step:  6190, loss: 3.567, accu: 0.344\n",
      "INFO:tensorflow:Step:  6200, loss: 3.567, accu: 0.347\n",
      "INFO:tensorflow:Step:  6200, model saved\n",
      "A man in a blue shirt is playing on A\n",
      "INFO:tensorflow:Step:  6210, loss: 3.642, accu: 0.327\n",
      "INFO:tensorflow:Step:  6220, loss: 3.802, accu: 0.327\n",
      "INFO:tensorflow:Step:  6230, loss: 3.774, accu: 0.327\n",
      "INFO:tensorflow:Step:  6240, loss: 3.450, accu: 0.380\n",
      "INFO:tensorflow:Step:  6250, loss: 3.559, accu: 0.331\n",
      "INFO:tensorflow:Step:  6260, loss: 3.639, accu: 0.344\n",
      "INFO:tensorflow:Step:  6270, loss: 3.544, accu: 0.333\n",
      "INFO:tensorflow:Step:  6280, loss: 3.585, accu: 0.344\n",
      "INFO:tensorflow:Step:  6290, loss: 3.636, accu: 0.337\n",
      "INFO:tensorflow:Step:  6300, loss: 3.464, accu: 0.354\n",
      "INFO:tensorflow:Step:  6300, model saved\n",
      "A man in a white shirt is standing in A\n",
      "INFO:tensorflow:Step:  6310, loss: 3.736, accu: 0.327\n",
      "INFO:tensorflow:Step:  6320, loss: 3.532, accu: 0.359\n",
      "INFO:tensorflow:Step:  6330, loss: 3.510, accu: 0.334\n",
      "INFO:tensorflow:Step:  6340, loss: 3.485, accu: 0.343\n",
      "INFO:tensorflow:Step:  6350, loss: 3.486, accu: 0.330\n",
      "INFO:tensorflow:Step:  6360, loss: 3.410, accu: 0.351\n",
      "INFO:tensorflow:Step:  6370, loss: 3.863, accu: 0.331\n",
      "INFO:tensorflow:Step:  6380, loss: 3.639, accu: 0.351\n",
      "INFO:tensorflow:Step:  6390, loss: 3.648, accu: 0.356\n",
      "INFO:tensorflow:Step:  6400, loss: 3.555, accu: 0.347\n",
      "INFO:tensorflow:Step:  6400, model saved\n",
      "A man in a hair and a black shirt A\n",
      "INFO:tensorflow:Step:  6410, loss: 3.599, accu: 0.373\n",
      "INFO:tensorflow:Step:  6420, loss: 3.693, accu: 0.327\n",
      "INFO:tensorflow:Step:  6430, loss: 3.389, accu: 0.351\n",
      "INFO:tensorflow:Step:  6440, loss: 3.540, accu: 0.342\n",
      "INFO:tensorflow:Step:  6450, loss: 3.390, accu: 0.333\n",
      "INFO:tensorflow:Step:  6460, loss: 3.599, accu: 0.334\n",
      "INFO:tensorflow:Step:  6470, loss: 3.659, accu: 0.344\n",
      "INFO:tensorflow:Step:  6480, loss: 3.593, accu: 0.340\n",
      "INFO:tensorflow:Step:  6490, loss: 3.446, accu: 0.352\n",
      "INFO:tensorflow:Step:  6500, loss: 3.644, accu: 0.338\n",
      "INFO:tensorflow:Step:  6500, model saved\n",
      "A man man in a blue shirt and a A\n",
      "INFO:tensorflow:Step:  6510, loss: 3.633, accu: 0.320\n",
      "INFO:tensorflow:Step:  6520, loss: 3.683, accu: 0.340\n",
      "INFO:tensorflow:Step:  6530, loss: 3.395, accu: 0.361\n",
      "INFO:tensorflow:Step:  6540, loss: 3.523, accu: 0.325\n",
      "INFO:tensorflow:Step:  6550, loss: 3.475, accu: 0.343\n",
      "INFO:tensorflow:Step:  6560, loss: 3.584, accu: 0.331\n",
      "INFO:tensorflow:Step:  6570, loss: 3.652, accu: 0.336\n",
      "INFO:tensorflow:Step:  6580, loss: 3.483, accu: 0.357\n",
      "INFO:tensorflow:Step:  6590, loss: 3.612, accu: 0.327\n",
      "INFO:tensorflow:Step:  6600, loss: 3.572, accu: 0.340\n",
      "INFO:tensorflow:Step:  6600, model saved\n",
      "A man in a orange shirt is at a A\n",
      "INFO:tensorflow:Step:  6610, loss: 3.685, accu: 0.333\n",
      "INFO:tensorflow:Step:  6620, loss: 3.592, accu: 0.334\n",
      "INFO:tensorflow:Step:  6630, loss: 3.606, accu: 0.341\n",
      "INFO:tensorflow:Step:  6640, loss: 3.674, accu: 0.321\n",
      "INFO:tensorflow:Step:  6650, loss: 3.461, accu: 0.339\n",
      "INFO:tensorflow:Step:  6660, loss: 3.586, accu: 0.332\n",
      "INFO:tensorflow:Step:  6670, loss: 3.446, accu: 0.355\n",
      "INFO:tensorflow:Step:  6680, loss: 3.611, accu: 0.360\n",
      "INFO:tensorflow:Step:  6690, loss: 3.756, accu: 0.289\n",
      "INFO:tensorflow:Step:  6700, loss: 3.638, accu: 0.345\n",
      "INFO:tensorflow:Step:  6700, model saved\n",
      "A are a of in a . . a A\n",
      "INFO:tensorflow:Step:  6710, loss: 3.541, accu: 0.366\n",
      "INFO:tensorflow:Step:  6720, loss: 3.790, accu: 0.311\n",
      "INFO:tensorflow:Step:  6730, loss: 3.583, accu: 0.350\n",
      "INFO:tensorflow:Step:  6740, loss: 3.686, accu: 0.316\n",
      "INFO:tensorflow:Step:  6750, loss: 3.526, accu: 0.354\n",
      "INFO:tensorflow:Step:  6760, loss: 3.663, accu: 0.320\n",
      "INFO:tensorflow:Step:  6770, loss: 3.585, accu: 0.338\n",
      "INFO:tensorflow:Step:  6780, loss: 3.478, accu: 0.346\n",
      "INFO:tensorflow:Step:  6790, loss: 3.735, accu: 0.341\n",
      "INFO:tensorflow:Step:  6800, loss: 3.433, accu: 0.359\n",
      "INFO:tensorflow:Step:  6800, model saved\n",
      "A group in a black shirt is a picture A\n",
      "INFO:tensorflow:Step:  6810, loss: 3.399, accu: 0.351\n",
      "INFO:tensorflow:Step:  6820, loss: 3.697, accu: 0.323\n",
      "INFO:tensorflow:Step:  6830, loss: 3.500, accu: 0.352\n",
      "INFO:tensorflow:Step:  6840, loss: 3.545, accu: 0.353\n",
      "INFO:tensorflow:Step:  6850, loss: 3.795, accu: 0.313\n",
      "INFO:tensorflow:Step:  6860, loss: 3.616, accu: 0.327\n",
      "INFO:tensorflow:Step:  6870, loss: 3.604, accu: 0.338\n",
      "INFO:tensorflow:Step:  6880, loss: 3.511, accu: 0.366\n",
      "INFO:tensorflow:Step:  6890, loss: 3.613, accu: 0.357\n",
      "INFO:tensorflow:Step:  6900, loss: 3.708, accu: 0.345\n",
      "INFO:tensorflow:Step:  6900, model saved\n",
      "A young in sitting down a street . a A\n",
      "INFO:tensorflow:Step:  6910, loss: 3.545, accu: 0.365\n",
      "INFO:tensorflow:Step:  6920, loss: 3.526, accu: 0.330\n",
      "INFO:tensorflow:Step:  6930, loss: 3.522, accu: 0.341\n",
      "INFO:tensorflow:Step:  6940, loss: 3.525, accu: 0.362\n",
      "INFO:tensorflow:Step:  6950, loss: 3.517, accu: 0.352\n",
      "INFO:tensorflow:Step:  6960, loss: 3.964, accu: 0.300\n",
      "INFO:tensorflow:Step:  6970, loss: 3.462, accu: 0.368\n",
      "INFO:tensorflow:Step:  6980, loss: 3.489, accu: 0.343\n",
      "INFO:tensorflow:Step:  6990, loss: 3.524, accu: 0.343\n",
      "INFO:tensorflow:Step:  7000, loss: 3.403, accu: 0.354\n",
      "INFO:tensorflow:Step:  7000, model saved\n",
      "A is a man are in a . a A\n",
      "INFO:tensorflow:Step:  7010, loss: 3.368, accu: 0.353\n",
      "INFO:tensorflow:Step:  7020, loss: 3.626, accu: 0.339\n",
      "INFO:tensorflow:Step:  7030, loss: 3.464, accu: 0.321\n",
      "INFO:tensorflow:Step:  7040, loss: 3.701, accu: 0.310\n",
      "INFO:tensorflow:Step:  7050, loss: 3.588, accu: 0.333\n",
      "INFO:tensorflow:Step:  7060, loss: 3.802, accu: 0.317\n",
      "INFO:tensorflow:Step:  7070, loss: 3.635, accu: 0.316\n",
      "INFO:tensorflow:Step:  7080, loss: 3.426, accu: 0.351\n",
      "INFO:tensorflow:Step:  7090, loss: 3.463, accu: 0.362\n",
      "INFO:tensorflow:Step:  7100, loss: 3.583, accu: 0.364\n",
      "INFO:tensorflow:Step:  7100, model saved\n",
      "A people are sitting on a street . a A\n",
      "INFO:tensorflow:Step:  7110, loss: 3.740, accu: 0.331\n",
      "INFO:tensorflow:Step:  7120, loss: 3.660, accu: 0.343\n",
      "INFO:tensorflow:Step:  7130, loss: 3.584, accu: 0.360\n",
      "INFO:tensorflow:Step:  7140, loss: 3.504, accu: 0.341\n",
      "INFO:tensorflow:Step:  7150, loss: 3.558, accu: 0.359\n",
      "INFO:tensorflow:Step:  7160, loss: 3.406, accu: 0.352\n",
      "INFO:tensorflow:Step:  7170, loss: 3.626, accu: 0.343\n",
      "INFO:tensorflow:Step:  7180, loss: 3.284, accu: 0.370\n",
      "INFO:tensorflow:Step:  7190, loss: 3.784, accu: 0.329\n",
      "INFO:tensorflow:Step:  7200, loss: 3.514, accu: 0.359\n",
      "INFO:tensorflow:Step:  7200, model saved\n",
      "A older man in on in a blue . A\n",
      "INFO:tensorflow:Step:  7210, loss: 3.518, accu: 0.325\n",
      "INFO:tensorflow:Step:  7220, loss: 3.497, accu: 0.341\n",
      "INFO:tensorflow:Step:  7230, loss: 3.489, accu: 0.316\n",
      "INFO:tensorflow:Step:  7240, loss: 3.598, accu: 0.350\n",
      "INFO:tensorflow:Step:  7250, loss: 3.485, accu: 0.362\n",
      "INFO:tensorflow:Step:  7260, loss: 3.691, accu: 0.313\n",
      "INFO:tensorflow:Step:  7270, loss: 3.626, accu: 0.366\n",
      "INFO:tensorflow:Step:  7280, loss: 3.558, accu: 0.339\n",
      "INFO:tensorflow:Step:  7290, loss: 3.404, accu: 0.347\n",
      "INFO:tensorflow:Step:  7300, loss: 3.560, accu: 0.331\n",
      "INFO:tensorflow:Step:  7300, model saved\n",
      "A woman in a black shirt and standing to A\n",
      "INFO:tensorflow:Step:  7310, loss: 3.524, accu: 0.364\n",
      "INFO:tensorflow:Step:  7320, loss: 3.323, accu: 0.377\n",
      "INFO:tensorflow:Step:  7330, loss: 3.280, accu: 0.363\n",
      "INFO:tensorflow:Step:  7340, loss: 3.447, accu: 0.359\n",
      "INFO:tensorflow:Step:  7350, loss: 3.826, accu: 0.305\n",
      "INFO:tensorflow:Step:  7360, loss: 3.548, accu: 0.331\n",
      "INFO:tensorflow:Step:  7370, loss: 3.703, accu: 0.316\n",
      "INFO:tensorflow:Step:  7380, loss: 3.516, accu: 0.354\n",
      "INFO:tensorflow:Step:  7390, loss: 3.649, accu: 0.351\n",
      "INFO:tensorflow:Step:  7400, loss: 3.452, accu: 0.341\n",
      "INFO:tensorflow:Step:  7400, model saved\n",
      "A dog is running a dog in in a A\n",
      "INFO:tensorflow:Step:  7410, loss: 3.556, accu: 0.356\n",
      "INFO:tensorflow:Step:  7420, loss: 3.529, accu: 0.352\n",
      "INFO:tensorflow:Step:  7430, loss: 3.719, accu: 0.319\n",
      "INFO:tensorflow:Step:  7440, loss: 3.612, accu: 0.340\n",
      "INFO:tensorflow:Step:  7450, loss: 3.464, accu: 0.333\n",
      "INFO:tensorflow:Step:  7460, loss: 3.508, accu: 0.360\n",
      "INFO:tensorflow:Step:  7470, loss: 3.700, accu: 0.309\n",
      "INFO:tensorflow:Step:  7480, loss: 3.514, accu: 0.358\n",
      "INFO:tensorflow:Step:  7490, loss: 3.607, accu: 0.345\n",
      "INFO:tensorflow:Step:  7500, loss: 3.572, accu: 0.331\n",
      "INFO:tensorflow:Step:  7500, model saved\n",
      "A group in a orange is a black are A\n",
      "INFO:tensorflow:Step:  7510, loss: 3.634, accu: 0.336\n",
      "INFO:tensorflow:Step:  7520, loss: 3.445, accu: 0.373\n",
      "INFO:tensorflow:Step:  7530, loss: 3.471, accu: 0.357\n",
      "INFO:tensorflow:Step:  7540, loss: 3.482, accu: 0.344\n",
      "INFO:tensorflow:Step:  7550, loss: 3.666, accu: 0.322\n",
      "INFO:tensorflow:Step:  7560, loss: 3.477, accu: 0.382\n",
      "INFO:tensorflow:Step:  7570, loss: 3.440, accu: 0.351\n",
      "INFO:tensorflow:Step:  7580, loss: 3.505, accu: 0.359\n",
      "INFO:tensorflow:Step:  7590, loss: 3.736, accu: 0.329\n",
      "INFO:tensorflow:Step:  7600, loss: 3.610, accu: 0.343\n",
      "INFO:tensorflow:Step:  7600, model saved\n",
      "A man in a ball in a man . A\n",
      "INFO:tensorflow:Step:  7610, loss: 3.527, accu: 0.368\n",
      "INFO:tensorflow:Step:  7620, loss: 3.456, accu: 0.355\n",
      "INFO:tensorflow:Step:  7630, loss: 3.640, accu: 0.327\n",
      "INFO:tensorflow:Step:  7640, loss: 3.588, accu: 0.330\n",
      "INFO:tensorflow:Step:  7650, loss: 3.471, accu: 0.365\n",
      "INFO:tensorflow:Step:  7660, loss: 3.537, accu: 0.361\n",
      "INFO:tensorflow:Step:  7670, loss: 3.517, accu: 0.338\n",
      "INFO:tensorflow:Step:  7680, loss: 3.525, accu: 0.338\n",
      "INFO:tensorflow:Step:  7690, loss: 3.490, accu: 0.331\n",
      "INFO:tensorflow:Step:  7700, loss: 3.518, accu: 0.368\n",
      "INFO:tensorflow:Step:  7700, model saved\n",
      "A little in in the grassy field . . A\n",
      "INFO:tensorflow:Step:  7710, loss: 3.733, accu: 0.327\n",
      "INFO:tensorflow:Step:  7720, loss: 3.551, accu: 0.345\n",
      "INFO:tensorflow:Step:  7730, loss: 3.485, accu: 0.341\n",
      "INFO:tensorflow:Step:  7740, loss: 3.652, accu: 0.341\n",
      "INFO:tensorflow:Step:  7750, loss: 3.560, accu: 0.325\n",
      "INFO:tensorflow:Step:  7760, loss: 3.705, accu: 0.330\n",
      "INFO:tensorflow:Step:  7770, loss: 3.572, accu: 0.331\n",
      "INFO:tensorflow:Step:  7780, loss: 3.560, accu: 0.312\n",
      "INFO:tensorflow:Step:  7790, loss: 3.698, accu: 0.320\n",
      "INFO:tensorflow:Step:  7800, loss: 3.527, accu: 0.368\n",
      "INFO:tensorflow:Step:  7800, model saved\n",
      "A workers are sitting on in . . . A\n",
      "INFO:tensorflow:Step:  7810, loss: 3.679, accu: 0.320\n",
      "INFO:tensorflow:Step:  7820, loss: 3.494, accu: 0.366\n",
      "INFO:tensorflow:Step:  7830, loss: 3.562, accu: 0.340\n",
      "INFO:tensorflow:Step:  7840, loss: 3.616, accu: 0.331\n",
      "INFO:tensorflow:Step:  7850, loss: 3.671, accu: 0.331\n",
      "INFO:tensorflow:Step:  7860, loss: 3.390, accu: 0.357\n",
      "INFO:tensorflow:Step:  7870, loss: 3.634, accu: 0.315\n",
      "INFO:tensorflow:Step:  7880, loss: 3.475, accu: 0.364\n",
      "INFO:tensorflow:Step:  7890, loss: 3.602, accu: 0.350\n",
      "INFO:tensorflow:Step:  7900, loss: 3.468, accu: 0.340\n",
      "INFO:tensorflow:Step:  7900, model saved\n",
      "A woman is is sitting a . the air A\n",
      "INFO:tensorflow:Step:  7910, loss: 3.560, accu: 0.336\n",
      "INFO:tensorflow:Step:  7920, loss: 3.544, accu: 0.324\n",
      "INFO:tensorflow:Step:  7930, loss: 3.517, accu: 0.353\n",
      "INFO:tensorflow:Step:  7940, loss: 3.709, accu: 0.315\n",
      "INFO:tensorflow:Step:  7950, loss: 3.296, accu: 0.375\n",
      "INFO:tensorflow:Step:  7960, loss: 3.567, accu: 0.338\n",
      "INFO:tensorflow:Step:  7970, loss: 3.337, accu: 0.359\n",
      "INFO:tensorflow:Step:  7980, loss: 3.226, accu: 0.370\n",
      "INFO:tensorflow:Step:  7990, loss: 3.469, accu: 0.364\n",
      "INFO:tensorflow:Step:  8000, loss: 3.461, accu: 0.368\n",
      "INFO:tensorflow:Step:  8000, model saved\n",
      "A a street of a woman in playing on A\n",
      "INFO:tensorflow:Step:  8010, loss: 3.715, accu: 0.330\n",
      "INFO:tensorflow:Step:  8020, loss: 3.593, accu: 0.346\n",
      "INFO:tensorflow:Step:  8030, loss: 3.456, accu: 0.338\n",
      "INFO:tensorflow:Step:  8040, loss: 3.759, accu: 0.320\n",
      "INFO:tensorflow:Step:  8050, loss: 3.827, accu: 0.308\n",
      "INFO:tensorflow:Step:  8060, loss: 3.491, accu: 0.347\n",
      "INFO:tensorflow:Step:  8070, loss: 3.336, accu: 0.355\n",
      "INFO:tensorflow:Step:  8080, loss: 3.523, accu: 0.333\n",
      "INFO:tensorflow:Step:  8090, loss: 3.550, accu: 0.369\n",
      "INFO:tensorflow:Step:  8100, loss: 3.402, accu: 0.352\n",
      "INFO:tensorflow:Step:  8100, model saved\n",
      "A a <UNK> . a a in a gear A\n",
      "INFO:tensorflow:Step:  8110, loss: 3.587, accu: 0.343\n",
      "INFO:tensorflow:Step:  8120, loss: 3.472, accu: 0.339\n",
      "INFO:tensorflow:Step:  8130, loss: 3.712, accu: 0.329\n",
      "INFO:tensorflow:Step:  8140, loss: 3.596, accu: 0.330\n",
      "INFO:tensorflow:Step:  8150, loss: 3.479, accu: 0.347\n",
      "INFO:tensorflow:Step:  8160, loss: 3.507, accu: 0.343\n",
      "INFO:tensorflow:Step:  8170, loss: 3.376, accu: 0.346\n",
      "INFO:tensorflow:Step:  8180, loss: 3.340, accu: 0.376\n",
      "INFO:tensorflow:Step:  8190, loss: 3.295, accu: 0.333\n",
      "INFO:tensorflow:Step:  8200, loss: 3.426, accu: 0.359\n",
      "INFO:tensorflow:Step:  8200, model saved\n",
      "A man is a black is a guitar . A\n",
      "INFO:tensorflow:Step:  8210, loss: 3.353, accu: 0.368\n",
      "INFO:tensorflow:Step:  8220, loss: 3.498, accu: 0.333\n",
      "INFO:tensorflow:Step:  8230, loss: 3.464, accu: 0.361\n",
      "INFO:tensorflow:Step:  8240, loss: 3.610, accu: 0.354\n",
      "INFO:tensorflow:Step:  8250, loss: 3.438, accu: 0.343\n",
      "INFO:tensorflow:Step:  8260, loss: 3.468, accu: 0.356\n",
      "INFO:tensorflow:Step:  8270, loss: 3.773, accu: 0.296\n",
      "INFO:tensorflow:Step:  8280, loss: 3.557, accu: 0.359\n",
      "INFO:tensorflow:Step:  8290, loss: 3.664, accu: 0.330\n",
      "INFO:tensorflow:Step:  8300, loss: 3.509, accu: 0.345\n",
      "INFO:tensorflow:Step:  8300, model saved\n",
      "A group boy in sitting a picture of of A\n",
      "INFO:tensorflow:Step:  8310, loss: 3.416, accu: 0.355\n",
      "INFO:tensorflow:Step:  8320, loss: 3.440, accu: 0.341\n",
      "INFO:tensorflow:Step:  8330, loss: 3.622, accu: 0.326\n",
      "INFO:tensorflow:Step:  8340, loss: 3.482, accu: 0.351\n",
      "INFO:tensorflow:Step:  8350, loss: 3.518, accu: 0.338\n",
      "INFO:tensorflow:Step:  8360, loss: 3.407, accu: 0.326\n",
      "INFO:tensorflow:Step:  8370, loss: 3.424, accu: 0.368\n",
      "INFO:tensorflow:Step:  8380, loss: 3.572, accu: 0.319\n",
      "INFO:tensorflow:Step:  8390, loss: 3.475, accu: 0.365\n",
      "INFO:tensorflow:Step:  8400, loss: 3.511, accu: 0.364\n",
      "INFO:tensorflow:Step:  8400, model saved\n",
      "A group of people are a are a man A\n",
      "INFO:tensorflow:Step:  8410, loss: 3.566, accu: 0.364\n",
      "INFO:tensorflow:Step:  8420, loss: 3.510, accu: 0.345\n",
      "INFO:tensorflow:Step:  8430, loss: 3.316, accu: 0.375\n",
      "INFO:tensorflow:Step:  8440, loss: 3.433, accu: 0.390\n",
      "INFO:tensorflow:Step:  8450, loss: 3.301, accu: 0.366\n",
      "INFO:tensorflow:Step:  8460, loss: 3.505, accu: 0.340\n",
      "INFO:tensorflow:Step:  8470, loss: 3.332, accu: 0.377\n",
      "INFO:tensorflow:Step:  8480, loss: 3.449, accu: 0.343\n",
      "INFO:tensorflow:Step:  8490, loss: 3.301, accu: 0.374\n",
      "INFO:tensorflow:Step:  8500, loss: 3.441, accu: 0.369\n",
      "INFO:tensorflow:Step:  8500, model saved\n",
      "A group of people are at a a . A\n",
      "INFO:tensorflow:Step:  8510, loss: 3.368, accu: 0.363\n",
      "INFO:tensorflow:Step:  8520, loss: 3.845, accu: 0.315\n",
      "INFO:tensorflow:Step:  8530, loss: 3.474, accu: 0.341\n",
      "INFO:tensorflow:Step:  8540, loss: 3.324, accu: 0.368\n",
      "INFO:tensorflow:Step:  8550, loss: 3.457, accu: 0.343\n",
      "INFO:tensorflow:Step:  8560, loss: 3.386, accu: 0.381\n",
      "INFO:tensorflow:Step:  8570, loss: 3.420, accu: 0.368\n",
      "INFO:tensorflow:Step:  8580, loss: 3.498, accu: 0.373\n",
      "INFO:tensorflow:Step:  8590, loss: 3.562, accu: 0.343\n",
      "INFO:tensorflow:Step:  8600, loss: 3.434, accu: 0.347\n",
      "INFO:tensorflow:Step:  8600, model saved\n",
      "A group in a children girls are playing in A\n",
      "INFO:tensorflow:Step:  8610, loss: 3.436, accu: 0.334\n",
      "INFO:tensorflow:Step:  8620, loss: 3.769, accu: 0.310\n",
      "INFO:tensorflow:Step:  8630, loss: 3.501, accu: 0.350\n",
      "INFO:tensorflow:Step:  8640, loss: 3.649, accu: 0.334\n",
      "INFO:tensorflow:Step:  8650, loss: 3.742, accu: 0.321\n",
      "INFO:tensorflow:Step:  8660, loss: 3.534, accu: 0.341\n",
      "INFO:tensorflow:Step:  8670, loss: 3.503, accu: 0.355\n",
      "INFO:tensorflow:Step:  8680, loss: 3.565, accu: 0.344\n",
      "INFO:tensorflow:Step:  8690, loss: 3.511, accu: 0.347\n",
      "INFO:tensorflow:Step:  8700, loss: 3.365, accu: 0.347\n",
      "INFO:tensorflow:Step:  8700, model saved\n",
      "A are on a room field area . one A\n",
      "INFO:tensorflow:Step:  8710, loss: 3.397, accu: 0.351\n",
      "INFO:tensorflow:Step:  8720, loss: 3.479, accu: 0.350\n",
      "INFO:tensorflow:Step:  8730, loss: 3.613, accu: 0.338\n",
      "INFO:tensorflow:Step:  8740, loss: 3.520, accu: 0.327\n",
      "INFO:tensorflow:Step:  8750, loss: 3.602, accu: 0.371\n",
      "INFO:tensorflow:Step:  8760, loss: 3.285, accu: 0.386\n",
      "INFO:tensorflow:Step:  8770, loss: 3.258, accu: 0.386\n",
      "INFO:tensorflow:Step:  8780, loss: 3.399, accu: 0.364\n",
      "INFO:tensorflow:Step:  8790, loss: 3.477, accu: 0.351\n",
      "INFO:tensorflow:Step:  8800, loss: 3.705, accu: 0.329\n",
      "INFO:tensorflow:Step:  8800, model saved\n",
      "A boy is a bike in a beach . A\n",
      "INFO:tensorflow:Step:  8810, loss: 3.415, accu: 0.344\n",
      "INFO:tensorflow:Step:  8820, loss: 3.643, accu: 0.338\n",
      "INFO:tensorflow:Step:  8830, loss: 3.495, accu: 0.369\n",
      "INFO:tensorflow:Step:  8840, loss: 3.678, accu: 0.312\n",
      "INFO:tensorflow:Step:  8850, loss: 3.546, accu: 0.338\n",
      "INFO:tensorflow:Step:  8860, loss: 3.250, accu: 0.374\n",
      "INFO:tensorflow:Step:  8870, loss: 3.420, accu: 0.347\n",
      "INFO:tensorflow:Step:  8880, loss: 3.686, accu: 0.339\n",
      "INFO:tensorflow:Step:  8890, loss: 3.291, accu: 0.374\n",
      "INFO:tensorflow:Step:  8900, loss: 3.441, accu: 0.357\n",
      "INFO:tensorflow:Step:  8900, model saved\n",
      "A men are playing on a table . one A\n",
      "INFO:tensorflow:Step:  8910, loss: 3.766, accu: 0.318\n",
      "INFO:tensorflow:Step:  8920, loss: 3.529, accu: 0.339\n",
      "INFO:tensorflow:Step:  8930, loss: 3.748, accu: 0.336\n",
      "INFO:tensorflow:Step:  8940, loss: 3.557, accu: 0.351\n",
      "INFO:tensorflow:Step:  8950, loss: 3.441, accu: 0.360\n",
      "INFO:tensorflow:Step:  8960, loss: 3.721, accu: 0.315\n",
      "INFO:tensorflow:Step:  8970, loss: 3.435, accu: 0.343\n",
      "INFO:tensorflow:Step:  8980, loss: 3.675, accu: 0.349\n",
      "INFO:tensorflow:Step:  8990, loss: 3.491, accu: 0.373\n",
      "INFO:tensorflow:Step:  9000, loss: 3.507, accu: 0.328\n",
      "INFO:tensorflow:Step:  9000, model saved\n",
      "A man in a blue shirt is on a A\n",
      "INFO:tensorflow:Step:  9010, loss: 3.634, accu: 0.334\n",
      "INFO:tensorflow:Step:  9020, loss: 3.555, accu: 0.361\n",
      "INFO:tensorflow:Step:  9030, loss: 3.512, accu: 0.355\n",
      "INFO:tensorflow:Step:  9040, loss: 3.591, accu: 0.334\n",
      "INFO:tensorflow:Step:  9050, loss: 3.364, accu: 0.377\n",
      "INFO:tensorflow:Step:  9060, loss: 3.584, accu: 0.339\n",
      "INFO:tensorflow:Step:  9070, loss: 3.422, accu: 0.364\n",
      "INFO:tensorflow:Step:  9080, loss: 3.756, accu: 0.326\n",
      "INFO:tensorflow:Step:  9090, loss: 3.498, accu: 0.362\n",
      "INFO:tensorflow:Step:  9100, loss: 3.573, accu: 0.340\n",
      "INFO:tensorflow:Step:  9100, model saved\n",
      "A people are down a camera . a camera A\n",
      "INFO:tensorflow:Step:  9110, loss: 3.618, accu: 0.310\n",
      "INFO:tensorflow:Step:  9120, loss: 3.691, accu: 0.305\n",
      "INFO:tensorflow:Step:  9130, loss: 3.541, accu: 0.335\n",
      "INFO:tensorflow:Step:  9140, loss: 3.474, accu: 0.364\n",
      "INFO:tensorflow:Step:  9150, loss: 3.504, accu: 0.345\n",
      "INFO:tensorflow:Step:  9160, loss: 3.552, accu: 0.335\n",
      "INFO:tensorflow:Step:  9170, loss: 3.637, accu: 0.343\n",
      "INFO:tensorflow:Step:  9180, loss: 3.526, accu: 0.338\n",
      "INFO:tensorflow:Step:  9190, loss: 3.467, accu: 0.359\n",
      "INFO:tensorflow:Step:  9200, loss: 3.592, accu: 0.354\n",
      "INFO:tensorflow:Step:  9200, model saved\n",
      "A man in standing a bicycle in a picture A\n",
      "INFO:tensorflow:Step:  9210, loss: 3.405, accu: 0.377\n",
      "INFO:tensorflow:Step:  9220, loss: 3.592, accu: 0.359\n",
      "INFO:tensorflow:Step:  9230, loss: 3.670, accu: 0.331\n",
      "INFO:tensorflow:Step:  9240, loss: 3.557, accu: 0.338\n",
      "INFO:tensorflow:Step:  9250, loss: 3.542, accu: 0.343\n",
      "INFO:tensorflow:Step:  9260, loss: 3.541, accu: 0.327\n",
      "INFO:tensorflow:Step:  9270, loss: 3.545, accu: 0.369\n",
      "INFO:tensorflow:Step:  9280, loss: 3.608, accu: 0.311\n",
      "INFO:tensorflow:Step:  9290, loss: 3.427, accu: 0.350\n",
      "INFO:tensorflow:Step:  9300, loss: 3.433, accu: 0.365\n",
      "INFO:tensorflow:Step:  9300, model saved\n",
      "A man is wearing a <UNK> in a red A\n",
      "INFO:tensorflow:Step:  9310, loss: 3.350, accu: 0.363\n",
      "INFO:tensorflow:Step:  9320, loss: 3.410, accu: 0.352\n",
      "INFO:tensorflow:Step:  9330, loss: 3.434, accu: 0.369\n",
      "INFO:tensorflow:Step:  9340, loss: 3.486, accu: 0.356\n",
      "INFO:tensorflow:Step:  9350, loss: 3.659, accu: 0.321\n",
      "INFO:tensorflow:Step:  9360, loss: 3.457, accu: 0.326\n",
      "INFO:tensorflow:Step:  9370, loss: 3.389, accu: 0.361\n",
      "INFO:tensorflow:Step:  9380, loss: 3.446, accu: 0.363\n",
      "INFO:tensorflow:Step:  9390, loss: 3.624, accu: 0.343\n",
      "INFO:tensorflow:Step:  9400, loss: 3.749, accu: 0.322\n",
      "INFO:tensorflow:Step:  9400, model saved\n",
      "A in sitting a a large and . a A\n",
      "INFO:tensorflow:Step:  9410, loss: 3.717, accu: 0.320\n",
      "INFO:tensorflow:Step:  9420, loss: 3.197, accu: 0.390\n",
      "INFO:tensorflow:Step:  9430, loss: 3.581, accu: 0.341\n",
      "INFO:tensorflow:Step:  9440, loss: 3.377, accu: 0.338\n",
      "INFO:tensorflow:Step:  9450, loss: 3.556, accu: 0.336\n",
      "INFO:tensorflow:Step:  9460, loss: 3.584, accu: 0.333\n",
      "INFO:tensorflow:Step:  9470, loss: 3.315, accu: 0.382\n",
      "INFO:tensorflow:Step:  9480, loss: 3.644, accu: 0.347\n",
      "INFO:tensorflow:Step:  9490, loss: 3.484, accu: 0.365\n",
      "INFO:tensorflow:Step:  9500, loss: 3.412, accu: 0.369\n",
      "INFO:tensorflow:Step:  9500, model saved\n",
      "A man of people are on . a picture A\n",
      "INFO:tensorflow:Step:  9510, loss: 3.334, accu: 0.357\n",
      "INFO:tensorflow:Step:  9520, loss: 3.726, accu: 0.330\n",
      "INFO:tensorflow:Step:  9530, loss: 3.474, accu: 0.349\n",
      "INFO:tensorflow:Step:  9540, loss: 3.438, accu: 0.357\n",
      "INFO:tensorflow:Step:  9550, loss: 3.412, accu: 0.387\n",
      "INFO:tensorflow:Step:  9560, loss: 3.433, accu: 0.339\n",
      "INFO:tensorflow:Step:  9570, loss: 3.682, accu: 0.339\n",
      "INFO:tensorflow:Step:  9580, loss: 3.543, accu: 0.352\n",
      "INFO:tensorflow:Step:  9590, loss: 3.091, accu: 0.389\n",
      "INFO:tensorflow:Step:  9600, loss: 3.225, accu: 0.373\n",
      "INFO:tensorflow:Step:  9600, model saved\n",
      "A young in a blue shirt shirt white white A\n",
      "INFO:tensorflow:Step:  9610, loss: 3.443, accu: 0.368\n",
      "INFO:tensorflow:Step:  9620, loss: 3.366, accu: 0.355\n",
      "INFO:tensorflow:Step:  9630, loss: 3.407, accu: 0.350\n",
      "INFO:tensorflow:Step:  9640, loss: 3.404, accu: 0.359\n",
      "INFO:tensorflow:Step:  9650, loss: 3.469, accu: 0.365\n",
      "INFO:tensorflow:Step:  9660, loss: 3.502, accu: 0.352\n",
      "INFO:tensorflow:Step:  9670, loss: 3.525, accu: 0.344\n",
      "INFO:tensorflow:Step:  9680, loss: 3.527, accu: 0.336\n",
      "INFO:tensorflow:Step:  9690, loss: 3.379, accu: 0.335\n",
      "INFO:tensorflow:Step:  9700, loss: 3.589, accu: 0.352\n",
      "INFO:tensorflow:Step:  9700, model saved\n",
      "A man in on the air . in at A\n",
      "INFO:tensorflow:Step:  9710, loss: 3.299, accu: 0.371\n",
      "INFO:tensorflow:Step:  9720, loss: 3.557, accu: 0.335\n",
      "INFO:tensorflow:Step:  9730, loss: 3.378, accu: 0.371\n",
      "INFO:tensorflow:Step:  9740, loss: 3.379, accu: 0.349\n",
      "INFO:tensorflow:Step:  9750, loss: 3.371, accu: 0.361\n",
      "INFO:tensorflow:Step:  9760, loss: 3.367, accu: 0.368\n",
      "INFO:tensorflow:Step:  9770, loss: 3.128, accu: 0.394\n",
      "INFO:tensorflow:Step:  9780, loss: 3.510, accu: 0.363\n",
      "INFO:tensorflow:Step:  9790, loss: 3.472, accu: 0.364\n",
      "INFO:tensorflow:Step:  9800, loss: 3.503, accu: 0.350\n",
      "INFO:tensorflow:Step:  9800, model saved\n",
      "A man boy is a blue shirt and black A\n",
      "INFO:tensorflow:Step:  9810, loss: 3.291, accu: 0.375\n",
      "INFO:tensorflow:Step:  9820, loss: 3.639, accu: 0.338\n",
      "INFO:tensorflow:Step:  9830, loss: 3.540, accu: 0.359\n",
      "INFO:tensorflow:Step:  9840, loss: 3.359, accu: 0.374\n",
      "INFO:tensorflow:Step:  9850, loss: 3.421, accu: 0.334\n",
      "INFO:tensorflow:Step:  9860, loss: 3.570, accu: 0.331\n",
      "INFO:tensorflow:Step:  9870, loss: 3.147, accu: 0.387\n",
      "INFO:tensorflow:Step:  9880, loss: 3.597, accu: 0.330\n",
      "INFO:tensorflow:Step:  9890, loss: 3.402, accu: 0.355\n",
      "INFO:tensorflow:Step:  9900, loss: 3.422, accu: 0.363\n",
      "INFO:tensorflow:Step:  9900, model saved\n",
      "A group of people people are to a outdoor A\n",
      "INFO:tensorflow:Step:  9910, loss: 3.332, accu: 0.369\n",
      "INFO:tensorflow:Step:  9920, loss: 3.416, accu: 0.360\n",
      "INFO:tensorflow:Step:  9930, loss: 3.317, accu: 0.374\n",
      "INFO:tensorflow:Step:  9940, loss: 3.352, accu: 0.365\n",
      "INFO:tensorflow:Step:  9950, loss: 3.259, accu: 0.357\n",
      "INFO:tensorflow:Step:  9960, loss: 3.416, accu: 0.359\n",
      "INFO:tensorflow:Step:  9970, loss: 3.351, accu: 0.363\n",
      "INFO:tensorflow:Step:  9980, loss: 3.283, accu: 0.376\n",
      "INFO:tensorflow:Step:  9990, loss: 3.274, accu: 0.364\n",
      "INFO:tensorflow:Step: 10000, loss: 3.415, accu: 0.353\n",
      "INFO:tensorflow:Step: 10000, model saved\n",
      "A man dog white dog is running in to A\n"
     ]
    }
   ],
   "source": [
    "training_steps = 10000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    writer = tf.summary.FileWriter(output_dir, sess.graph)\n",
    "    for i in range(training_steps):\n",
    "        (batch_img_features,\n",
    "         batch_sentence_ids,\n",
    "         batch_weights, _) = caption_data.next_batch(hps.batch_size)\n",
    "        input_vals = (batch_img_features,\n",
    "                      batch_sentence_ids,\n",
    "                      batch_weights,\n",
    "                      hps.keep_prob)\n",
    "        feed_dict = dict(zip(place_holders, input_vals))\n",
    "        fetches = [global_step, loss, accuracy, prediction, train_op]\n",
    "        should_log = (i + 1) % hps.log_frequent == 0\n",
    "        should_save = (i + 1) % hps.save_frequent == 0\n",
    "        if should_log:\n",
    "            fetches += [summary_op]\n",
    "\n",
    "        outputs = sess.run(fetches, feed_dict = feed_dict)\n",
    "        global_step_val, loss_val, accuracy_val, prediction_ = outputs[0:4]\n",
    "        if should_log:\n",
    "            summary_str = outputs[-1]\n",
    "            writer.add_summary(summary_str, global_step_val)\n",
    "            logging.info('Step: %5d, loss: %3.3f, accu: %3.3f'\n",
    "                         % (global_step_val, loss_val, accuracy_val))\n",
    "\n",
    "        if should_save:\n",
    "            model_save_file = os.path.join(output_dir, \"image_caption\")\n",
    "            logging.info('Step: %5d, model saved' % global_step_val)\n",
    "            saver.save(sess, model_save_file, global_step = global_step_val)\n",
    "            predict_sentence = [vocab.id_to_word(word) for word in prediction_]\n",
    "            predict_sentence_list = [predict_sentence[i:i + 10] for i in\n",
    "                                     range(0, len(predict_sentence), 10)]\n",
    "            for i in range(9):\n",
    "                print(predict_sentence[i],end = \" \")\n",
    "            print(predict_sentence[10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-71e1ac8c",
   "language": "python",
   "display_name": "PyCharm (MachineLearning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}