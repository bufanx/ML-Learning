{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batches.meta', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'readme.html', 'test_batch']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "CIFAR_DIR = \"./cifar-10-batches-py\"\n",
    "print(os.listdir(CIFAR_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"read data from data file.\"\"\"\n",
    "    with open(filename,'rb') as f:\n",
    "        data = pickle.load(f,encoding='iso-8859-1')\n",
    "        return data['data'],data['labels']\n",
    "\n",
    "#tensorflow.Dataset\n",
    "class CifarData:\n",
    "    def __init__(self,filenames,need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        for filename in filenames:\n",
    "            data,labels = load_data(filename)\n",
    "            for item,label in zip(data,labels):\n",
    "                if label in [0,1]:\n",
    "                    all_data.append(item)\n",
    "                    all_labels.append(label)\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._data = self._data / 127.5 - 1\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "    def _shuffle_data(self):\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "\n",
    "    def next_batch(self,batch_size):\n",
    "        \"\"\":return batch_szie examples as a batch.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator:end_indicator]\n",
    "        batch_labels = self._labels[self._indicator:end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data,batch_labels\n",
    "\n",
    "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i ) for i in range(1,6)]\n",
    "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
    "\n",
    "train_data = CifarData(train_filenames,True)\n",
    "test_data = CifarData(test_filenames,True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,3072])\n",
    "y = tf.placeholder(tf.int64,[None])\n",
    "\n",
    "#(3072,1)\n",
    "w = tf.get_variable('w',[X.get_shape()[-1],1],\n",
    "                    initializer=tf.random_normal_initializer(0,1))\n",
    "\n",
    "#(1,)\n",
    "b = tf.get_variable('b',[1],\n",
    "                    initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "#[None,3072]*[3072,1] = [None,1]\n",
    "y_ = tf.matmul(X,w) + b\n",
    "\n",
    "#[None,1]\n",
    "p_y_1 = tf.nn.sigmoid(y_)\n",
    "y_reshaped = tf.reshape(y,(-1,1))\n",
    "y_reshaped_float = tf.cast(y_reshaped,tf.float32)\n",
    "loss = tf.reduce_mean(tf.square(y_reshaped_float - p_y_1))\n",
    "\n",
    "predict = p_y_1 > 0.5\n",
    "correct_prediction = tf.equal(tf.cast(predict,tf.int64),y_reshaped)\n",
    "accuary = tf.reduce_mean(tf.cast(correct_prediction,tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train ] Step :500, loss: 0.29168, acc: 0.65000\n",
      "[Train ] Step :1000, loss: 0.11981, acc: 0.85000\n",
      "[Train ] Step :1500, loss: 0.28124, acc: 0.70000\n",
      "[Train ] Step :2000, loss: 0.21443, acc: 0.75000\n",
      "[Train ] Step :2500, loss: 0.21314, acc: 0.75000\n",
      "[Train ] Step :3000, loss: 0.16561, acc: 0.80000\n",
      "[Train ] Step :3500, loss: 0.28833, acc: 0.70000\n",
      "[Train ] Step :4000, loss: 0.15061, acc: 0.85000\n",
      "[Train ] Step :4500, loss: 0.00000, acc: 1.00000\n",
      "[Train ] Step :5000, loss: 0.18782, acc: 0.80000\n",
      "[Test ] Step :5000, acc: 0.80400\n",
      "[Train ] Step :5500, loss: 0.24444, acc: 0.75000\n",
      "[Train ] Step :6000, loss: 0.19420, acc: 0.80000\n",
      "[Train ] Step :6500, loss: 0.25000, acc: 0.75000\n",
      "[Train ] Step :7000, loss: 0.27148, acc: 0.70000\n",
      "[Train ] Step :7500, loss: 0.15349, acc: 0.85000\n",
      "[Train ] Step :8000, loss: 0.15037, acc: 0.85000\n",
      "[Train ] Step :8500, loss: 0.14338, acc: 0.85000\n",
      "[Train ] Step :9000, loss: 0.15351, acc: 0.80000\n",
      "[Train ] Step :9500, loss: 0.20001, acc: 0.80000\n",
      "[Train ] Step :10000, loss: 0.29796, acc: 0.70000\n",
      "[Test ] Step :10000, acc: 0.80750\n",
      "[Train ] Step :10500, loss: 0.26326, acc: 0.75000\n",
      "[Train ] Step :11000, loss: 0.15414, acc: 0.85000\n",
      "[Train ] Step :11500, loss: 0.09978, acc: 0.90000\n",
      "[Train ] Step :12000, loss: 0.24948, acc: 0.75000\n",
      "[Train ] Step :12500, loss: 0.15224, acc: 0.85000\n",
      "[Train ] Step :13000, loss: 0.13705, acc: 0.85000\n",
      "[Train ] Step :13500, loss: 0.15418, acc: 0.85000\n",
      "[Train ] Step :14000, loss: 0.24991, acc: 0.75000\n",
      "[Train ] Step :14500, loss: 0.05000, acc: 0.95000\n",
      "[Train ] Step :15000, loss: 0.20069, acc: 0.80000\n",
      "[Test ] Step :15000, acc: 0.80850\n",
      "[Train ] Step :15500, loss: 0.14996, acc: 0.85000\n",
      "[Train ] Step :16000, loss: 0.20121, acc: 0.80000\n",
      "[Train ] Step :16500, loss: 0.05000, acc: 0.95000\n",
      "[Train ] Step :17000, loss: 0.10805, acc: 0.90000\n",
      "[Train ] Step :17500, loss: 0.14321, acc: 0.85000\n",
      "[Train ] Step :18000, loss: 0.18723, acc: 0.80000\n",
      "[Train ] Step :18500, loss: 0.19281, acc: 0.80000\n",
      "[Train ] Step :19000, loss: 0.05014, acc: 0.95000\n",
      "[Train ] Step :19500, loss: 0.21966, acc: 0.75000\n",
      "[Train ] Step :20000, loss: 0.05565, acc: 0.95000\n",
      "[Test ] Step :20000, acc: 0.81650\n",
      "[Train ] Step :20500, loss: 0.23143, acc: 0.75000\n",
      "[Train ] Step :21000, loss: 0.00067, acc: 1.00000\n",
      "[Train ] Step :21500, loss: 0.23821, acc: 0.75000\n",
      "[Train ] Step :22000, loss: 0.19973, acc: 0.80000\n",
      "[Train ] Step :22500, loss: 0.21063, acc: 0.75000\n",
      "[Train ] Step :23000, loss: 0.14806, acc: 0.85000\n",
      "[Train ] Step :23500, loss: 0.08729, acc: 0.90000\n",
      "[Train ] Step :24000, loss: 0.05001, acc: 0.95000\n",
      "[Train ] Step :24500, loss: 0.14998, acc: 0.85000\n",
      "[Train ] Step :25000, loss: 0.19935, acc: 0.80000\n",
      "[Test ] Step :25000, acc: 0.81300\n",
      "[Train ] Step :25500, loss: 0.22690, acc: 0.75000\n",
      "[Train ] Step :26000, loss: 0.09734, acc: 0.90000\n",
      "[Train ] Step :26500, loss: 0.15000, acc: 0.85000\n",
      "[Train ] Step :27000, loss: 0.09967, acc: 0.90000\n",
      "[Train ] Step :27500, loss: 0.00034, acc: 1.00000\n",
      "[Train ] Step :28000, loss: 0.15197, acc: 0.85000\n",
      "[Train ] Step :28500, loss: 0.24964, acc: 0.75000\n",
      "[Train ] Step :29000, loss: 0.15007, acc: 0.85000\n",
      "[Train ] Step :29500, loss: 0.11100, acc: 0.90000\n",
      "[Train ] Step :30000, loss: 0.20004, acc: 0.80000\n",
      "[Test ] Step :30000, acc: 0.82000\n",
      "[Train ] Step :30500, loss: 0.05952, acc: 0.95000\n",
      "[Train ] Step :31000, loss: 0.00000, acc: 1.00000\n",
      "[Train ] Step :31500, loss: 0.20014, acc: 0.80000\n",
      "[Train ] Step :32000, loss: 0.11181, acc: 0.90000\n",
      "[Train ] Step :32500, loss: 0.20000, acc: 0.80000\n",
      "[Train ] Step :33000, loss: 0.25007, acc: 0.75000\n",
      "[Train ] Step :33500, loss: 0.19101, acc: 0.80000\n",
      "[Train ] Step :34000, loss: 0.09848, acc: 0.90000\n",
      "[Train ] Step :34500, loss: 0.15002, acc: 0.85000\n",
      "[Train ] Step :35000, loss: 0.19802, acc: 0.80000\n",
      "[Test ] Step :35000, acc: 0.82050\n",
      "[Train ] Step :35500, loss: 0.13634, acc: 0.80000\n",
      "[Train ] Step :36000, loss: 0.05926, acc: 0.95000\n",
      "[Train ] Step :36500, loss: 0.19953, acc: 0.80000\n",
      "[Train ] Step :37000, loss: 0.17927, acc: 0.80000\n",
      "[Train ] Step :37500, loss: 0.09982, acc: 0.90000\n",
      "[Train ] Step :38000, loss: 0.29987, acc: 0.70000\n",
      "[Train ] Step :38500, loss: 0.25000, acc: 0.75000\n",
      "[Train ] Step :39000, loss: 0.18906, acc: 0.80000\n",
      "[Train ] Step :39500, loss: 0.19865, acc: 0.80000\n",
      "[Train ] Step :40000, loss: 0.05000, acc: 0.95000\n",
      "[Test ] Step :40000, acc: 0.82000\n",
      "[Train ] Step :40500, loss: 0.25005, acc: 0.75000\n",
      "[Train ] Step :41000, loss: 0.08282, acc: 0.90000\n",
      "[Train ] Step :41500, loss: 0.10189, acc: 0.90000\n",
      "[Train ] Step :42000, loss: 0.20015, acc: 0.80000\n",
      "[Train ] Step :42500, loss: 0.13087, acc: 0.85000\n",
      "[Train ] Step :43000, loss: 0.10072, acc: 0.90000\n",
      "[Train ] Step :43500, loss: 0.26416, acc: 0.70000\n",
      "[Train ] Step :44000, loss: 0.14736, acc: 0.85000\n",
      "[Train ] Step :44500, loss: 0.24995, acc: 0.75000\n",
      "[Train ] Step :45000, loss: 0.05006, acc: 0.95000\n",
      "[Test ] Step :45000, acc: 0.82250\n",
      "[Train ] Step :45500, loss: 0.05066, acc: 0.95000\n",
      "[Train ] Step :46000, loss: 0.15074, acc: 0.85000\n",
      "[Train ] Step :46500, loss: 0.15087, acc: 0.85000\n",
      "[Train ] Step :47000, loss: 0.28298, acc: 0.70000\n",
      "[Train ] Step :47500, loss: 0.14999, acc: 0.85000\n",
      "[Train ] Step :48000, loss: 0.11977, acc: 0.90000\n",
      "[Train ] Step :48500, loss: 0.25172, acc: 0.75000\n",
      "[Train ] Step :49000, loss: 0.20000, acc: 0.80000\n",
      "[Train ] Step :49500, loss: 0.07310, acc: 0.90000\n",
      "[Train ] Step :50000, loss: 0.19992, acc: 0.80000\n",
      "[Test ] Step :50000, acc: 0.81900\n",
      "[Train ] Step :50500, loss: 0.14999, acc: 0.85000\n",
      "[Train ] Step :51000, loss: 0.25015, acc: 0.75000\n",
      "[Train ] Step :51500, loss: 0.11171, acc: 0.90000\n",
      "[Train ] Step :52000, loss: 0.10343, acc: 0.90000\n",
      "[Train ] Step :52500, loss: 0.07809, acc: 0.90000\n",
      "[Train ] Step :53000, loss: 0.20000, acc: 0.80000\n",
      "[Train ] Step :53500, loss: 0.14999, acc: 0.85000\n",
      "[Train ] Step :54000, loss: 0.29328, acc: 0.70000\n",
      "[Train ] Step :54500, loss: 0.10023, acc: 0.90000\n",
      "[Train ] Step :55000, loss: 0.15757, acc: 0.85000\n",
      "[Test ] Step :55000, acc: 0.81650\n",
      "[Train ] Step :55500, loss: 0.20445, acc: 0.80000\n",
      "[Train ] Step :56000, loss: 0.15431, acc: 0.85000\n",
      "[Train ] Step :56500, loss: 0.05000, acc: 0.95000\n",
      "[Train ] Step :57000, loss: 0.10008, acc: 0.90000\n",
      "[Train ] Step :57500, loss: 0.23071, acc: 0.75000\n",
      "[Train ] Step :58000, loss: 0.25001, acc: 0.75000\n",
      "[Train ] Step :58500, loss: 0.15602, acc: 0.85000\n",
      "[Train ] Step :59000, loss: 0.21921, acc: 0.75000\n",
      "[Train ] Step :59500, loss: 0.30000, acc: 0.70000\n",
      "[Train ] Step :60000, loss: 0.20124, acc: 0.80000\n",
      "[Test ] Step :60000, acc: 0.81550\n",
      "[Train ] Step :60500, loss: 0.10131, acc: 0.90000\n",
      "[Train ] Step :61000, loss: 0.15013, acc: 0.85000\n",
      "[Train ] Step :61500, loss: 0.13866, acc: 0.85000\n",
      "[Train ] Step :62000, loss: 0.09984, acc: 0.90000\n",
      "[Train ] Step :62500, loss: 0.14964, acc: 0.85000\n",
      "[Train ] Step :63000, loss: 0.10022, acc: 0.90000\n",
      "[Train ] Step :63500, loss: 0.00033, acc: 1.00000\n",
      "[Train ] Step :64000, loss: 0.10000, acc: 0.90000\n",
      "[Train ] Step :64500, loss: 0.10287, acc: 0.90000\n",
      "[Train ] Step :65000, loss: 0.09999, acc: 0.90000\n",
      "[Test ] Step :65000, acc: 0.82000\n",
      "[Train ] Step :65500, loss: 0.20165, acc: 0.80000\n",
      "[Train ] Step :66000, loss: 0.26611, acc: 0.70000\n",
      "[Train ] Step :66500, loss: 0.11445, acc: 0.90000\n",
      "[Train ] Step :67000, loss: 0.15000, acc: 0.85000\n",
      "[Train ] Step :67500, loss: 0.05890, acc: 0.95000\n",
      "[Train ] Step :68000, loss: 0.04445, acc: 0.95000\n",
      "[Train ] Step :68500, loss: 0.10157, acc: 0.90000\n",
      "[Train ] Step :69000, loss: 0.14997, acc: 0.85000\n",
      "[Train ] Step :69500, loss: 0.12329, acc: 0.85000\n",
      "[Train ] Step :70000, loss: 0.05022, acc: 0.95000\n",
      "[Test ] Step :70000, acc: 0.81850\n",
      "[Train ] Step :70500, loss: 0.05055, acc: 0.95000\n",
      "[Train ] Step :71000, loss: 0.15034, acc: 0.85000\n",
      "[Train ] Step :71500, loss: 0.10105, acc: 0.90000\n",
      "[Train ] Step :72000, loss: 0.09696, acc: 0.90000\n",
      "[Train ] Step :72500, loss: 0.15437, acc: 0.85000\n",
      "[Train ] Step :73000, loss: 0.05104, acc: 0.95000\n",
      "[Train ] Step :73500, loss: 0.20475, acc: 0.80000\n",
      "[Train ] Step :74000, loss: 0.18162, acc: 0.80000\n",
      "[Train ] Step :74500, loss: 0.30259, acc: 0.70000\n",
      "[Train ] Step :75000, loss: 0.10101, acc: 0.90000\n",
      "[Test ] Step :75000, acc: 0.81850\n",
      "[Train ] Step :75500, loss: 0.05898, acc: 0.95000\n",
      "[Train ] Step :76000, loss: 0.07876, acc: 0.90000\n",
      "[Train ] Step :76500, loss: 0.10142, acc: 0.90000\n",
      "[Train ] Step :77000, loss: 0.15097, acc: 0.85000\n",
      "[Train ] Step :77500, loss: 0.20631, acc: 0.80000\n",
      "[Train ] Step :78000, loss: 0.15048, acc: 0.85000\n",
      "[Train ] Step :78500, loss: 0.14993, acc: 0.85000\n",
      "[Train ] Step :79000, loss: 0.10979, acc: 0.90000\n",
      "[Train ] Step :79500, loss: 0.15042, acc: 0.85000\n",
      "[Train ] Step :80000, loss: 0.15141, acc: 0.85000\n",
      "[Test ] Step :80000, acc: 0.81650\n",
      "[Train ] Step :80500, loss: 0.05022, acc: 0.95000\n",
      "[Train ] Step :81000, loss: 0.16897, acc: 0.80000\n",
      "[Train ] Step :81500, loss: 0.12523, acc: 0.85000\n",
      "[Train ] Step :82000, loss: 0.00265, acc: 1.00000\n",
      "[Train ] Step :82500, loss: 0.05016, acc: 0.95000\n",
      "[Train ] Step :83000, loss: 0.14889, acc: 0.85000\n",
      "[Train ] Step :83500, loss: 0.20003, acc: 0.80000\n",
      "[Train ] Step :84000, loss: 0.05000, acc: 0.95000\n",
      "[Train ] Step :84500, loss: 0.40189, acc: 0.60000\n",
      "[Train ] Step :85000, loss: 0.12243, acc: 0.85000\n",
      "[Test ] Step :85000, acc: 0.81450\n",
      "[Train ] Step :85500, loss: 0.10158, acc: 0.90000\n",
      "[Train ] Step :86000, loss: 0.15043, acc: 0.85000\n",
      "[Train ] Step :86500, loss: 0.05493, acc: 0.95000\n",
      "[Train ] Step :87000, loss: 0.30006, acc: 0.70000\n",
      "[Train ] Step :87500, loss: 0.10828, acc: 0.90000\n",
      "[Train ] Step :88000, loss: 0.00016, acc: 1.00000\n",
      "[Train ] Step :88500, loss: 0.25275, acc: 0.75000\n",
      "[Train ] Step :89000, loss: 0.20512, acc: 0.80000\n",
      "[Train ] Step :89500, loss: 0.10077, acc: 0.90000\n",
      "[Train ] Step :90000, loss: 0.05011, acc: 0.95000\n",
      "[Test ] Step :90000, acc: 0.81450\n",
      "[Train ] Step :90500, loss: 0.16743, acc: 0.85000\n",
      "[Train ] Step :91000, loss: 0.15088, acc: 0.85000\n",
      "[Train ] Step :91500, loss: 0.20503, acc: 0.80000\n",
      "[Train ] Step :92000, loss: 0.15024, acc: 0.85000\n",
      "[Train ] Step :92500, loss: 0.20070, acc: 0.80000\n",
      "[Train ] Step :93000, loss: 0.17672, acc: 0.80000\n",
      "[Train ] Step :93500, loss: 0.10022, acc: 0.90000\n",
      "[Train ] Step :94000, loss: 0.25865, acc: 0.70000\n",
      "[Train ] Step :94500, loss: 0.20249, acc: 0.80000\n",
      "[Train ] Step :95000, loss: 0.05045, acc: 0.95000\n",
      "[Test ] Step :95000, acc: 0.81700\n",
      "[Train ] Step :95500, loss: 0.15004, acc: 0.85000\n",
      "[Train ] Step :96000, loss: 0.05668, acc: 0.95000\n",
      "[Train ] Step :96500, loss: 0.20000, acc: 0.80000\n",
      "[Train ] Step :97000, loss: 0.10671, acc: 0.90000\n",
      "[Train ] Step :97500, loss: 0.00000, acc: 1.00000\n",
      "[Train ] Step :98000, loss: 0.30367, acc: 0.70000\n",
      "[Train ] Step :98500, loss: 0.30376, acc: 0.70000\n",
      "[Train ] Step :99000, loss: 0.06021, acc: 0.95000\n",
      "[Train ] Step :99500, loss: 0.10319, acc: 0.90000\n",
      "[Train ] Step :100000, loss: 0.11396, acc: 0.85000\n",
      "[Test ] Step :100000, acc: 0.81350\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 20\n",
    "train_steps = 100000\n",
    "test_steps = 100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data,batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val,accu_val ,_ =sess.run(\n",
    "            [loss,accuary,train_op],\n",
    "            feed_dict={\n",
    "                X:batch_data,\n",
    "                y:batch_labels})\n",
    "        if (i+1) % 500 ==0:\n",
    "            print('[Train ] Step :%d, loss: %4.5f, acc: %4.5f'\\\n",
    "                  %(i+1,loss_val,accu_val))\n",
    "\n",
    "        if (i+1) % 5000 == 0:\n",
    "            test_data = CifarData(test_filenames, False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data ,test_batch_labels\\\n",
    "                    = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run(\n",
    "                    [accuary],\n",
    "                    feed_dict = {\n",
    "                        X: test_batch_data,\n",
    "                        y: test_batch_labels\n",
    "                    })\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.nanmean(all_test_acc_val)\n",
    "            print('[Test ] Step :%d, acc: %4.5f'\\\n",
    "                  %(i+1,test_acc))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-71e1ac8c",
   "language": "python",
   "display_name": "PyCharm (MachineLearning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}